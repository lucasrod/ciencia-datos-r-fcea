---
title: "Análisis Exploratorio: Conjunto Ames Housing"
subtitle: "Análisis para modelo de regresión con Sale_Price como variable respuesta"
format:
  html:
    self-contained: true
    toc: true
    toc-depth: 3
    code-fold: false
    code-tools: true
    code-summary: "Mostrar código"
bibliography: references.bib
execute:
  echo:    true
  warning: true
  message: false
editor: visual
---

```{r setup, message=FALSE}
# Cargar paquetes necesarios
library(tidyverse)
library(tidymodels) # ML
library(modeldata)  # Conjunto Ames housing
library(skimr)      # Análisis descriptivo
library(corrplot)   # Para matrices de correlación
library(GGally)     # Para pair plots avanzados
library(patchwork)  # Para combinar gráficos
library(ggthemes)   # Temas para ggplot2
library(e1071)      # Para asimetría y curtosis
library(robustbase) # Para medcouple: estadístico no paramétrico y robusto que mide la asimetría del "cuerpo central" de la distribución, sin verse afectado por outliers

# Reproducibilidad
set.seed(42)

# Configuración general
theme_set(theme_minimal())
options(dplyr.summarise.inform = FALSE)
```

# Análisis Exploratorio: Conjunto Ames Housing

## Resumen

Este análisis exploratorio tiene como objetivo complementar el trabajo realizado en `HW2.qmd`, proporcionando una caracterización del conjunto de datos `ames` antes de aplicar modelos supervisados. Se identifican patrones relevantes en la variable respuesta `Sale_Price`, se evalúan relaciones clave con las variables predictoras y se diagnostica la calidad general de los datos.

A continuación se sintetizan los principales hallazgos:

-   **Distribución de la variable objetivo (`Sale_Price`)**: Presenta una cola larga a la derecha, lo que sugiere que unas pocas viviendas tienen precios significativamente más altos que la mayoría. Esta observación, consistente con la exploración hecha en Kaggle, motiva el uso de transformaciones como `log(Sale_Price)` para estabilizar la varianza y mejorar la aproximación a la normalidad antes de aplicar modelos lineales.

-   **Estadísticos claves de `Sale_Price`**:

    -   Mediana: `XX`
    -   Media: `XX`
    -   Coeficiente de variación (CV): `XX%`
    -   Asimetría: `XX`
    -   Curtosis: `XX`

-   **Valores atípicos (outliers)**:

    -   Se detectaron `XX` observaciones (≈ `XX%`) fuera del rango intercuartílico.
    -   Se recomienda evaluar su impacto durante la validación del modelo.

-   **Calidad general del conjunto**:

    -   Total de observaciones: `2,930`
    -   Total de variables: `74`
    -   Variables con valores faltantes: `X` (ej. `Lot_Frontage`, `Alley`, etc.)
    -   No se detectan filas duplicadas por ID, aunque algunas variables presentan codificación especial de ausencia (ceros como "No aplica").

-   **Variables predictoras destacadas**:

    -   Las variables numéricas más correlacionadas con `Sale_Price` son: `Gr_Liv_Area`, `Garage_Area`, `Total_Bsmt_SF`, entre otras.
    -   Se observa colinealidad entre ciertos predictores relacionados con superficie.

-   **Sugerencias para el modelado**:

    -   Transformar `Sale_Price` mediante `log()` para mejorar los supuestos de normalidad.
    -   Evaluar interacciones no lineales y colinealidad entre variables.
    -   Considerar ingeniería de características que reflejen combinaciones relevantes (ej. superficie total habitable).

Este informe sirve como insumo previo para diseñar estrategias de preprocesamiento y selección de variables en el modelado predictivo.


## Introducción

En este proyecto trabajaremos con el conjunto de datos conocido como *Ames Housing*, inicialmente presentado por Dean De Cock [@ames_decock_2011] en el artículo académico *"Ames, Iowa: Alternative to the Boston Housing Data"*. Este conjunto registra ventas de propiedades residenciales en la ciudad de Ames, Iowa, Estados Unidos, ocurridas entre los años 2006 y 2010. El conjunto final del estudio original contiene 2930 registros con aproximadamente 80 variables que describen características físicas continuas (superficie total del terreno, metros cuadrados habitables, área del sótano), discretas (número de baños, cocinas, plazas de garage), ordinales (calidad general, condición general) y nominales (barrio, estilo de casa, estado de venta, entre otras)

El mercado inmobiliario en Ames se caracteriza por una marcada heterogeneidad en términos de precios y perfiles de vivienda. Se observan propiedades con calidades constructivas, tamaños y ubicaciones muy diversas, lo que introduce una alta variabilidad tanto en variables continuas como categóricas. Por ejemplo, el **precio de venta (variable explicada, de respuesta o dependiente)**, varía entre \$12 789 y más de \$700 000 a través de más de 25 barrios distintos, cada uno con dinámicas propias. Esta variabilidad ofrece una valiosa oportunidad para explorar cómo las características estructurales y la ubicación influyen directamente sobre el valor de los inmuebles. En el análisis original se demostró que, de hecho, cerca del 80 % de la variación en el precio de venta podía ser explicada únicamente considerando la superficie total construida y el barrio en el cual se ubica la propiedad.

Desde una perspectiva estadística, el conjunto presenta una estructura de datos moderadamente compleja. Combina variables numéricas continuas y discretas, ordinales y categóricas, muchas de ellas con ceros y codificaciones como "None", lo que hace necesario revisar con atención cómo están representados y organizados los datos. También se observan correlaciones fuertes entre las **variables independientes o predictoras** (como el área habitable y el número de habitaciones), así como indicios de heterocedasticidad respecto al precio (varianza del error depende de las variables independientes).

```{=html}
<!--

Desde una perspectiva económica y social, el análisis de este tipo de datos es relevante para comprender cómo se forman los precios en mercados inmobiliarios locales, especialmente en ciudades intermedias como Ames (58 965 habitantes según el Censo de 2010). En este sentido, el precio de venta puede interpretarse como una expresión observable de las preferencias agregadas de los consumidores, quienes asignan distinto valor, o utilidad, a atributos como el tamaño del terreno, la calidad de los materiales o la ubicación.

Analizar dicha variabilidad permite no solo entender mejor cómo varían los precios de las viviendas según sus características, sino también brindar información útil para quienes toman decisiones sobre compra o venta de propiedades. Además, puede servir de apoyo para el diseño de políticas públicas relacionadas con el acceso a la vivienda y la planificación urbana.

Por estas razones, el conjunto Ames Housing es un conjunto de datos ideal para aplicar técnicas de estadística descriptiva, explorando relaciones entre variables, resumiendo información relevante y visualizando estructuras complejas. En particular, abordaremos el análisis mediante gráficos y medidas de resumen, y entrenaremos un modelo de regresión lineal múltiple para predecir el precio de venta, así como métodos de agrupamiento (*clustering*) para identificar posibles grupos dentro del mercado inmobiliario que no están explícitamente definidos en los datos, pero que pueden descubrirse al analizar similitudes entre las viviendas.

-->
```

Por estas razones, el conjunto *Ames Housing* resulta adecuado para aplicar herramientas de estadística descriptiva y técnicas exploratorias que permitan comprender mejor el mercado inmobiliario. En este proyecto nos proponemos resumir y visualizar la información mediante gráficos y medidas de resumen, ajustar un modelo de regresión lineal múltiple para predecir el precio de venta y aplicar métodos de agrupamiento (*clustering*) para identificar perfiles de viviendas con características similares.

## Descripción del conjunto de datos

En nuestro análisis utilizaremos la versión del conjunto provista en el paquete de R `{modeldata}`, denominado simplemente `ames` [@modeldata2024]. Este conjunto presenta diferencias puntuales respecto al original propuesto por De Cock (2011) y documentado detalladamente en su diccionario de variables [@ames_datadict_2011].

En particular, **no están presentes** en nuestro conjunto las siguientes 10 variables:

-   `Order` (número de observación)
-   `PID` (identificador de parcela)
-   `Overall Qual` (calidad general de la casa)
-   `Exter Qual` (calidad del material exterior)
-   `Bsmt Qual` (calidad/altura del sótano)
-   `Low Qual Fin SF` (superficie de acabado de baja calidad)
-   `KitchenQual` (calidad de la cocina)
-   `FireplaceQu` (calidad de la chimenea)
-   `Garage Yr Blt` (año de construcción del garaje)
-   `GarageQual` (calidad del garaje)

Por otro lado, aparecen dos nuevas variables en nuestro conjunto:

-   `Longitude` (longitud geográfica)
-   `Latitude` (latitud geográfica)

Por tanto, mientras el conjunto original incluye 82 variables, nuestro análisis se basará en un total de 74.

> Cabe señalar que las variables omitidas corresponden a medidas cualitativas que fueron excluidas deliberadamente en la versión de `{modeldata}` por considerarse demasiado cercanas al resultado que se busca predecir (el precio de venta), o posibles proxies del mismo, lo que introduce sesgos al usarse como predictores. Esta decisión busca preservar la validez del modelado al evitar variables que podrían comportarse como outcomes encubiertos [@modeldata2024].

## Paneo Inicial y Diagnóstico de Calidad

Realizamos un diagnóstico inicial del conjunto de datos `ames` cargado desde el paquete `{modeldata}`. Exploraremos su estructura, tipos de variables, codificaciones especiales, presencia de valores faltantes (*missing values*), ausencia estructural y duplicados.

```{r load_data}
# Cargar el conjunto ames
data(ames)
ames_data <- as_tibble(ames)
```

### Estructura

```{r glimpse}
glimpse(ames_data)
```

### Análisis descriptivo univariado

Diferenciamos entre variables numéricas y categóricas, y para cada tipo se presentan estadísticos de resumen, distribución, y niveles o codificaciones relevantes, útil para detectar problemas tempranos.

#### Clases de variables

Este análisis se desarrolla en R base + tidyverse, que emplean el sistema de clases **S3**. Durante este informe nos referiremos indistinguiblemente a los tipos de variables como a las clases. Aunque especificamente, usaremos `class()` para obtener las clases de variables que son un *tipo semántico* y `typeof()` para obtener el tipo de dato de R que es un *tipo primitivo*.

```{r class_types}
# Conteo de clases
ames_data %>%
  summarise(across(everything(), class)) %>%
  pivot_longer(cols = everything(), names_to = "n_variables", values_to = "class") %>%
  count(class, name = "n_variables") %>%
  knitr::kable(caption = "Distribución de clases de variables")
```

> **Notas**:
>
> Las clases se asignan automáticamente por R al importar los datos.
>
> Si consultamos el tipo primitivo que informa `typeof()`:
>
> -   Los vectores de clase `numeric` se almacenan como `"double"`
> -   Los vectores de clase `factor` se almacenan como `"integer"`.

##### Clase Factor

Las clases factor son variables categóricas codificadas o enumeradas como enteros con sus niveles asociados.

##### Clases Numéricas

Identificamos las variables numéricas por su clase en R (`integer` o `numeric`) y por su naturaleza semántica como discretas (si todos sus valores son enteros) o continuas (si contienen decimales). Esta clasificación no siempre coincide con el tipo primitivo de dato (`double` o `integer`) asignado automáticamente por el parser de R.

A su vez, calculamos la cardinalidad de cada variable, es decir, la cantidad de valores únicos observados. Este número resulta fundamental para distinguir entre variables que podrían recodificarse como factores (baja cardinalidad discreta) y aquellas que deben tratarse como numéricas en sentido estricto.

```{r}
num_vars <- ames_data %>% select(where(is.numeric))

numeric_classification <- tibble(
  variable    = names(num_vars),
  clase       = map_chr(variable, ~ class(ames_data[[.x]])[1]),
  is_discrete = map_lgl(variable, ~ all(ames_data[[.x]] == floor(ames_data[[.x]]), na.rm = TRUE))
) %>%
  mutate(
    tipo        = if_else(is_discrete, "Discreta", "Continua"),
    cardinalidad = map_int(variable, ~ n_distinct(ames_data[[.x]], na.rm = TRUE))
  ) %>%
  select(variable, clase, tipo, cardinalidad)

knitr::kable(
  numeric_classification %>% arrange(tipo, cardinalidad),
  caption = "Clasificación semántica de variables numéricas con cardinalidad"
)
```

> Nota: Observamos que variables como `Garage_Cars`, `Bsmt_Half_Bath` y `Bsmt_Full_Bath` son claramente numéricas discretas, pero fueron importadas como `numeric` (double) en vez de `integer`, a pesar de no tener decimales. Esta inconsistencia no afecta los cálculos pero sí debe considerarse al preparar modelos, ya que puede justificar transformar algunas de estas variables a `factor` u `ordered`.
>
> La lógica y criterios para convertir las variables numéricas discretas a factores (incluyendo la tabla de cardinalidades y las justificaciones) se han llevado a la sección **Recomendaciones de preprocesamiento** bajo el subtítulo **Conversión de variables discretas a factores**, donde encontraremos el listado completo y la acción sugerida para cada variable.

#### Tipo de variable para el análisis

Factores vs numéricos.

```{r skim_types}
skim_summary <- skim(ames_data)
skim_summary %>%
  count(skim_type, name = "n_variables") %>%
  knitr::kable(caption = "Distribución de tipo de variables (skim_type)")
```

#### Variables categóricas

Mostramos la cantidad de categorías y las categorías más observadas de las variables de tipo factor:

```{r cat_skim_summary}
skim_summary %>%
  filter(skim_type == "factor") %>%
  arrange(desc(factor.n_unique)) %>%
  select(
    variable    = skim_variable,
    n_levels    = factor.n_unique,
    top_counts  = factor.top_counts,
  ) %>%
  knitr::kable(
    caption = "Variables categóricas: niveles y counts principales"
  )
```

```{r cat_levels_distribution}

# Cardinalidad de cada factor desde skim_summary
cardinality <- skim_summary %>%
  filter(skim_type == "factor") %>%
  select(
    variable = skim_variable,
    n_levels = factor.n_unique
  )

# Conteo y proporciones por nivel
factor_vars <- cardinality$variable

prop_cat <- map_dfr(factor_vars, function(var) {
  ames_data %>%
    count(level = .data[[var]]) %>%
    mutate(
      variable = var,
      prop     = percent(n / sum(n), accuracy = 0.1)
    )
})

# Unir cardinalidad ordenando por n_levels (desc) y luego por n (desc)
prop_cat %>%
  left_join(cardinality, by = "variable") %>%
  arrange(
    desc(n_levels),  # se usa para ordenar, pero no se mostrará
    variable,
    desc(n)
  ) %>%
  select(variable, level, n, prop) %>%  # acá ya no incluimos n_levels
  knitr::kable(
    caption = "Distribución de niveles de variables categóricas"
  )
```

#### Variables numéricas

Calculamos medidas de tendencia central, posición, dispersión y dirección de asimetría (`media - mediana`):

```{r num_skim_summary}
skim_summary %>%
  filter(skim_type == "numeric") %>%
  transmute(
    variable = skim_variable,
    mean     = numeric.mean,
    sd       = numeric.sd,
    rel_skew = abs(numeric.mean - numeric.p50) / numeric.sd, # asimetría relativa a la dispersión
    asimetría = case_when(
      is.na(rel_skew)             ~ "indefinida",
      rel_skew < 0.1              ~ "Aprox. simétrica",
      numeric.mean > numeric.p50  ~ "Positiva",
      TRUE                        ~ "Negativa"
    ),
    histograma = numeric.hist,
    p0       = numeric.p0,
    p25      = numeric.p25,
    median   = numeric.p50,
    p75      = numeric.p75,
    p100     = numeric.p100
  ) %>%
  knitr::kable(
    digits = 2,
    caption = "Variables numéricas"
  )
```

> Nota: `rel_skew` es una aproximación útil para comparar diferencias relativas entre media y mediana entre distribuciones con escalas o unidades distintas. Sin embargo, **no siempre refleja adecuadamente la estructura de la distribución**. Por ejemplo:
>
> -   En `Lot_Area`, el valor de `rel_skew` es bajo a pesar de una asimetría real muy alta, ya que **la alta desviación estándar atenúa el impacto de colas extremas**.
> -   En `Kitchen_AbvGr`, la aparente simetría se debe a un **soporte discreto y reducido** con una moda dominante, lo que mantiene la media y mediana cercanas aunque exista asimetría.
> -   En `BsmtFin_SF_1`, se observa lo opuesto: la diferencia entre media y mediana parece indicar asimetría, pero se debe a **modas discretas separadas** dentro de una distribución que en realidad tiene colas relativamente simétricas.
>
> Por ello, se complementa el análisis con el coeficiente de asimetría (`skewness`) y otras métricas robustas.

```{r eval = FALSE}
skim_summary %>% rowwise() %>% mutate(x = list(ames_data[[skim_variable]])) %>% glimpse()
```

```{r extended_numeric_eda}
# Variables numéricas con EDA extendido
numeric_eda <- skim_summary %>%
  filter(skim_type == "numeric") %>%
  # Para poder usar e1071 necesitamos extraer cada vector numérico de las variables
  rowwise() %>%
  mutate(
    x = list(ames_data[[skim_variable]]), # vector original de cada variable
    cv = numeric.sd / numeric.mean,       # coef. de variación
    iqr = numeric.p75 - numeric.p25,      # rango IQ
    skewness = skewness(x),               # asimetría
    medcouple = mc(x,doScale = TRUE), # asimetría robusta
    kurtosis = kurtosis(x),               # curtosis
    prop_outliers = if_else(iqr == 0, NA_real_,
                        mean(x < (numeric.p25 - 1.5*iqr) |
                        x > (numeric.p75 + 1.5*iqr), 
                        na.rm = TRUE)), # outliers regla Tukey
    transform_rec = case_when(
      skewness < 0 ~ "ninguna: asimetría negativa",
      !all(x >= 0, na.rm = TRUE) ~ "ninguna: valores negativos",
      all(x > 0,  na.rm = TRUE) & skewness > 1.5 ~ "log",
      all(x > 0,  na.rm = TRUE) & skewness > 0.5 ~ "Box-Cox (evaluar)",
      all(x >= 0, na.rm = TRUE) & skewness > 0.5 ~ "log(x+1) o sqrt: contiene ceros",
      TRUE            ~ "ninguna"
    )
  ) %>%
  ungroup() %>%
  transmute(
    variable        = skim_variable,
    mean            = numeric.mean,
    sd              = numeric.sd,
    cv,
    skewness        = round(skewness, 2),
    medcouple       = round(medcouple, 2),
    kurtosis        = round(kurtosis, 2),
    pct_outliers    = percent(prop_outliers, accuracy = 0.1),
    iqr,
    histograma      = numeric.hist,
    transform_rec   = transform_rec
  )

  knitr::kable(
    numeric_eda,
    digits = 2,
    caption = "Análisis extendido de variables numéricas"
  )

```

> **Nota sobre las medidas de asimetría:** En este análisis se reportan dos métricas complementarias para evaluar la asimetría de las variables numéricas:
>
> -   `skewness` corresponde al coeficiente de asimetría muestral ($g_1$), una medida **paramétrica** que mide la forma de la distribución en función del sesgo respecto a la media (mediante el tercer momento central muestral). Es sensible a valores atípicos (*outliers*) y capta la **asimetría en las colas**.
> -   `medcouple`: es un **estadístico no paramétrico y robusto** que mide la asimetría del “cuerpo central" de la distribución, sin verse afectado por outliers.
>
> Dado que ambas métricas responden a diferentes aspectos de la forma de la distribución, pueden arrojar resultados aparentemente contradictorios:
>
> -   En variables con muchos ceros y algunos valores extremos altos (como `Pool_Area` o `Misc_Val`), el `medcouple` puede ser **negativo** (indicando que la masa principal está a la derecha), mientras que el `skewness` será **positivo** por la presencia de colas largas hacia la derecha.
>
> -   En otros casos, como `Kitchen_AbvGr`, aunque la media y la mediana están alineadas (dando idea de simetría), el `skewness` puede ser alto por la naturaleza discreta de la variable (muchos 1 y pocos valores mayores).
>
> Por ello, **es recomendable interpretar ambas medidas en conjunto**: `skewness` capta simetría global, incluyendo extremos, y `medcouple` resume la simetría de la parte mas densa de la distribución. Usarlas juntas da una visión más completa sobre la simetría de cada variable.

### Calidad de Datos y Ausencia Estructural

El tratamiento de valores faltantes es una etapa clave del preprocesamiento en proyectos de datos, ya que afecta directamente las decisiones de modelado, la validez de los patrones descubiertos y la capacidad de generalización de los modelos. No todos los modelos toleran valores faltantes, y su presencia puede introducir sesgos o errores si no se trata de forma adecuada (transformaciones). Como veremos, este conjunto no contiene valores faltantes explícitos, codificaciones que indican ausencia estructural, con el objetivo de tomar decisiones informadas para su tratamiento posterior.

Falta presentar resultados esperados a partir de la literatura relevante existente (Paper "Ames, Iowa: Alternative to the Boston Housing Data" y Kaggle notebooks) y contrastar resultados.

En esta sección abordamos:

-   Valores faltantes explícitos (`NA`)
-   Codificaciones especiales como `"None"`, `"No_"`, y ceros estructurales en variables numéricas
-   Ausencia estructural implícita a partir del contexto de la variable

Además, se documentan decisiones preliminares sobre imputación, transformación o recodificación para trazabilidad futura.

#### Valores faltantes explícitos (*missing values*)

```{r missing_values}
# Resumen de NAs
n_obs <- nrow(ames_data)
na_summary <- ames_data %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "n_na") %>%
  filter(n_na > 0) %>%
  mutate(pct = round(100 * n_na / n_obs, 2)) %>%
  arrange(desc(pct))

# Tabla vacía
# knitr::kable(na_summary, caption = "Variables con valores faltantes")
cat("Número de variables con NA:", nrow(na_summary), "\n")
```

> No se detectan *missing values* explícitos en el conjunto, lo que evita imputaciones tradicionales y nos lleva a las codificaciones especiales.

#### Variables categóricas: codificaciones especiales

Para un listado exhaustivo de todos los niveles de las variables categóricas, véase la sección "Variables categóricas" del análisis descriptivo univariado.

##### Codificaciones de ausencia

Las variables categóricas que indican ausencia estructural son aquellas que el data entry representa la ausencia de la característica usando strings como "None" o "No\_\*".

```{r}
# Niveles que indican ausencia
none_levels <- c("None", "No_Alley_Access", "No_Pool", "No_Fence", "No_Garage", "No_Basement")

ames_data %>%
  select(where(is.factor)) %>%
  summarise(across(everything(), ~ sum(. %in% none_levels))) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "n_none") %>%
  filter(n_none > 0) %>%
  mutate(percent = percent(n_none / n_obs, accuracy = 0.1)) %>%
  arrange(desc(n_none/ n_obs)) %>%
  select(-n_none) %>%
  knitr::kable(caption = "Variables categóricas con niveles que indican ausencia estructural")
```

> Todos los lineamientos relativos a la consolidación de niveles en variables categóricas (alta cardinalidad, agrupación de niveles raros, binarización, etc.) se encuentran ahora en **Recomendaciones de preprocesamiento** dentro de la subsección **Reagrupación de niveles en categóricas**, con ejemplos y tablas que explicitan la estrategia de recodificación para cada caso.

#### Variables numéricas: ceros estructurales

En el Ames Housing Dataset, algunos ceros en variables numéricas no representan valores cuantitativos reales, sino que indican la **ausencia estructural** de una característica. Por ejemplo, un valor `0` en `Garage_Area` implica que no hay garaje, y en `MasVnr_Area`, que no hay revestimiento de mampostería. Esta interpretación está respaldada por variables categóricas asociadas como `Garage_Type == "None"` o `MasVnr_Type == "None"`.

> Como se señala en varios notebooks de Kaggle, "el valor 0 puede estar indicando que el criterio no aplicaba".

Es importante tener en cuenta esta semántica al transformar, imputar o escalar estas variables, ya que estos ceros no deben tratarse como valores numéricos ordinarios.

A continuación se muestra la proporción de ceros estructurales en variables numéricas:

```{r}
# Porcentaje de observaciones `0` en variables numéricas
ames_data %>%
  select(where(is.numeric)) %>%
  summarise(across(everything(), ~ mean(. == 0, na.rm = TRUE))) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "zeros_prop") %>%
  filter(zeros_prop > 0) %>%
  mutate(pct_zeros = percent(zeros_prop, accuracy = 0.1)) %>%
  arrange(desc(zeros_prop)) %>%
  select(-zeros_prop) %>%
  knitr::kable(caption = "Proporción de ceros estructurales en variables numéricas")
```

##### Mapeo de variables y métricas asociadas

A continuación se exploran pares de variables categóricas (`cat_var`) y numéricas (`num_var`) que presentan un comportamiento estructural conjunto. En estos casos, el valor `"None"` en la variable categórica suele coincidir con un valor `0` en la numérica, lo que refuerza la interpretación del cero como indicador de ausencia de la característica.

```{r}
pares <- list(
  c("Garage_Type",     "Garage_Area"),
  c("Garage_Cond",     "Garage_Area"),
  c("Bsmt_Cond",       "Total_Bsmt_SF"), 
  c("Bsmt_Exposure",   "Total_Bsmt_SF"), 
  c("Pool_QC",         "Pool_Area"),
  c("Mas_Vnr_Type",     "Mas_Vnr_Area"),
  c("Misc_Feature",    "Misc_Val")
)

# Número total de observaciones
n_obs <- nrow(ames_data)

# Función que, dado un par (cat_var, num_var), devuelve un tibble con métricas
resumen_pareado <- function(par) {
  cat_var <- par[1]
  num_var <- par[2]

  # Filtrar none / cero
  df <- ames_data %>%
    mutate(
      is_none = .data[[cat_var]] %in% none_levels,
      is_zero = .data[[num_var]] == 0
    )

  n_none        <- sum(df$is_none,    na.rm = TRUE)
  n_zero        <- sum(df$is_zero,    na.rm = TRUE)
  n_none_zero   <- sum(df$is_none & df$is_zero, na.rm = TRUE)

  tibble(
    cat_var              = cat_var,
    num_var              = num_var,
    n_none               = n_none,
    pct_none             = percent(n_none / n_obs, accuracy = 0.1),
    n_zero               = n_zero,
    pct_zero             = percent(n_zero / n_obs, accuracy = 0.1),
    n_none_zero          = n_none_zero,
    pct_zero_given_none  = if (n_none>0) percent(n_none_zero / n_none, accuracy = 0.1) else NA_real_,
    pct_none_given_zero  = if (n_zero>0) percent(n_none_zero / n_zero, accuracy = 0.1) else NA_real_
  )
}

# Mapeamos y combinamos en un solo data.frame
tabla_ausencia <- map_dfr(pares, resumen_pareado)

knitr::kable(
  tabla_ausencia,
  caption = "Métricas de ausencia estructural por par (None vs 0)",
  col.names = c(
    "Var. Categ.", "Var. Num.",
    "count None", "pct None",
    "count 0",    "pct 0",
    "count None∧0",
    "pct 0|None", "pct None|0"
  )
)
```

> Esta tabla permite verificar la consistencia interna del dataset y orientar decisiones de ingeniería de variables, especialmente para `Garage_Area`, `Total_Bsmt_SF` y `Mas_Vnr_Area`, que presentan asociaciones estructurales claras con variables categóricas y alta correlación con `Sale_Price`.
>
> Las recomendaciones específicas (creación de indicadores binarios, transformaciones logarítmicas, generación de interacciones, y recodificación de ceros como `NA`) se consolidan en la sección **Ingeniería de variables y transformaciones**, junto con una tabla resumen de problemas detectados y acciones propuestas.

#### Duplicados

No existe variable `Id` en el conjunto, por lo que no se puede validar unicidad de filas por identificador. Validaremos unicidad de filas por fila completa.

```{r duplicates}
# Validar unicidad de Id si existiera o por fila completa
n_duplicadas <- ames_data %>% duplicated() %>% sum()
cat("Número de filas duplicadas:", n_duplicadas, "\n")
```

> No se detectan filas duplicadas exactas.

## Análisis de la variable respuesta: Sale_Price

### Resumen estadístico

```{r target_summary}
# Resumen estadístico de Sale_Price
summary(ames_data$Sale_Price)

# Coeficiente de variación
cv_sale_price <- sd(ames_data$Sale_Price, na.rm = TRUE) / mean(ames_data$Sale_Price, na.rm = TRUE) * 100
cv_sale_price <- round(cv_sale_price, 2)

cat("Coeficiente de variación de Sale_Price:", cv_sale_price, "%\n")

skewness_value <- skewness(ames_data$Sale_Price, na.rm = TRUE)
kurtosis_value <- kurtosis(ames_data$Sale_Price, na.rm = TRUE)

cat("Asimetría:", round(skewness_value, 2), "\n")
cat("Curtosis:", round(kurtosis_value, 2), "\n")
```

### Visualización de la distribución

```{r target_distribution}
# Histograma con curva de densidad
p1 <- ames_data %>%
  ggplot(aes(x = Sale_Price)) +
  geom_histogram(aes(y = after_stat(density)), 
                 bins = 50, 
                 fill = "steelblue", 
                 color = "white", 
                 alpha = 0.8) +
  geom_density(color = "red", linewidth = 1) +
  scale_x_continuous(labels = scales::dollar) +
  labs(title = "Distribución de Precios de Venta",
       x = "Precio de Venta (USD)",
       y = "Densidad") +
  theme(plot.title = element_text(hjust = 0.5))

# QQ-plot para normalidad
p2 <- ggplot(ames_data, aes(sample = Sale_Price)) +
  stat_qq(color = "steelblue") +
  stat_qq_line(color = "red") +
  labs(title = "QQ-Plot de Normalidad",
       x = "Cuantiles Teóricos",
       y = "Cuantiles Muestrales") +
  theme(plot.title = element_text(hjust = 0.5))

# Boxplot para identificar valores atípicos
p3 <- ames_data %>%
  ggplot(aes(y = Sale_Price)) +
  geom_boxplot(fill = "steelblue", alpha = 0.7) +
  scale_y_continuous(labels = scales::dollar) +
  labs(title = "Boxplot de Precios de Venta",
       y = "Precio de Venta (USD)") +
  theme(plot.title = element_text(hjust = 0.5))

# Mostrar gráficos
(p1 + p2) / p3 + plot_layout(heights = c(2, 1))
```

### Transformación logarítmica

```{r log_transform}
# Aplicar transformación logarítmica
ames_data <- ames_data %>%
  mutate(log_Sale_Price = log(Sale_Price))

# Visualizar distribución transformada
p4 <- ames_data %>%
  ggplot(aes(x = log_Sale_Price)) +
  geom_histogram(aes(y = after_stat(density)), 
                 bins = 50, 
                 fill = "steelblue", 
                 color = "white", 
                 alpha = 0.8) +
  geom_density(color = "red", linewidth = 1) +
  labs(title = "Distribución de log(Sale_Price)",
       x = "log(Precio de Venta)",
       y = "Densidad") +
  theme(plot.title = element_text(hjust = 0.5))

# QQ-plot para normalidad de la variable transformada
p5 <- ggplot(ames_data, aes(sample = log_Sale_Price)) +
  stat_qq(color = "steelblue") +
  stat_qq_line(color = "red") +
  labs(title = "QQ-Plot de log(Sale_Price)",
       x = "Cuantiles Teóricos",
       y = "Cuantiles Muestrales") +
  theme(plot.title = element_text(hjust = 0.5))

# Mostrar gráficos transformados
p4 + p5
```

#### Tabla comparativa de resumen descriptivo: Sale_Price vs log_Sale_Price

Habría que:
- Elegir una de las dos tablas
- Incluir tests de normalidad para ambas variables o por lo menos que quede tabulado los p-valor para diferentes pruebas de hipótesis
- Arreglar warnings
- Pivotar las tablas para que las variables queden en las columnas y las métricas en las filas

```{r summary_log_sale_price}

# Variables a resumir
vars <- c("Sale_Price", "log_Sale_Price")

# Recalculamos el resumen skim incluyendo log(Sale_Price)
skim_summary <- skim(ames_data)

# Extraer resumen estándar de skimr
std <- skim_summary %>%
  filter(skim_variable %in% vars) %>%
  transmute(
    variable   = skim_variable,
    mean       = numeric.mean,
    sd         = numeric.sd,
    rel_skew   = abs(numeric.mean - numeric.p50) / numeric.sd,
    asimetría  = case_when(
                   rel_skew < 0.1              ~ "Aprox. simétrica",
                   numeric.mean > numeric.p50  ~ "Positiva",
                   TRUE                        ~ "Negativa"
                 ),
    p0         = numeric.p0,
    p25        = numeric.p25,
    median     = numeric.p50,
    p75        = numeric.p75,
    p100       = numeric.p100
  )

# Calcular resumen extendido
ext <- skim_summary %>%
  filter(skim_variable %in% vars) %>%
  rowwise() %>%
  mutate(
    x           = list(ames_data[[skim_variable]]),
    cv          = numeric.sd / numeric.mean,
    iqr         = numeric.p75 - numeric.p25,
    skewness    = skewness(x, na.rm = TRUE),
    medcouple   = mc(x, doScale = TRUE),
    kurtosis    = kurtosis(x, na.rm = TRUE),
    outliers    = mean(x < (numeric.p25 - 1.5*iqr) |
                       x > (numeric.p75 + 1.5*iqr), na.rm = TRUE)
  ) %>%
  ungroup() %>%
  transmute(
    variable      = skim_variable,
    cv            = round(cv, 2),
    IQR           = round(iqr, 2),
    skewness      = round(skewness, 2),
    medcouple     = round(medcouple, 2),
    kurtosis      = round(kurtosis, 2),
    pct_outliers  = scales::percent(outliers, accuracy = 0.1)
  )

# Unir y mostrar
std %>%
  left_join(ext, by = "variable") %>%
  knitr::kable(
    digits  = 2,
    caption = "Comparación de estadísticas descriptivas para Sale_Price y log_Sale_Price"
  )
```

```{r}
ames_data %>%
  # Seleccionar y pivotar
  select(Sale_Price, log_Sale_Price) %>%
  pivot_longer(everything(),
               names_to  = "variable",
               values_to = "valor") %>%
  # Agrupar y resumir todo de una
  group_by(variable) %>%
  summarise(
    # tendencia central y posición
    media    = mean(valor, na.rm = TRUE),
    mediana  = median(valor, na.rm = TRUE),
    p25      = quantile(valor, 0.25, na.rm = TRUE),
    p75      = quantile(valor, 0.75, na.rm = TRUE),
    # dispersión
    sd       = sd(valor, na.rm = TRUE),
    IQR      = IQR(valor, na.rm = TRUE),
    cv       = sd / media,
    # asimetría y curtosis
    skewness = e1071::skewness(valor, na.rm = TRUE),
    medcouple= robustbase::mc(valor, doScale = TRUE),
    kurtosis = e1071::kurtosis(valor, na.rm = TRUE),
    # outliers según Tukey
    pct_outliers = mean(
      valor < (p25 - 1.5 * IQR) | valor > (p75 + 1.5 * IQR),
      na.rm = TRUE
    )
  ) %>%
  # Formatear porcentajes y decimales
  mutate(
    pct_outliers = scales::percent(pct_outliers, accuracy = 0.1),
    across(c(media:cv, skewness:medcouple, kurtosis), round, 2)
  ) %>%
  knitr::kable(
    caption = "Estadísticas descriptivas completas (tendencia, dispersión, asimetría, outliers)",
    digits  = 2
  )
```

## Análisis de variables predictoras

### Variables numéricas

#### Correlación con variables numéricas

```{r numeric_correlation}
# Seleccionar solo variables numéricas
numeric_vars <- ames_data %>%
  select(where(is.numeric)) %>%
  select(-any_of("log_Sale_Price")) %>% # Excluimos la variable respuesta transformada
  select(-matches("^[A-Za-z]+\\.y\\.+[0-9]+\\.?[0-9]*$"))  # Eliminar columnas duplicadas

# Matriz de correlación
cor_matrix <- cor(numeric_vars, use = "complete.obs")

# Variables más correlacionadas con Sale_Price
cor_with_target <- cor_matrix[, "Sale_Price", drop = FALSE] %>%
  as.data.frame() %>%
  rownames_to_column("Variable") %>%
  arrange(desc(Sale_Price)) %>%
  filter(Variable != "Sale_Price")

# Mostrar las 15 variables más correlacionadas
head(cor_with_target, 15) %>% 
  knitr::kable(digits = 3, 
               col.names = c("Variable", "Correlación con Sale_Price"),
               caption = "Variables numéricas más correlacionadas con Sale_Price")

# Gráfico de correlación para las 10 variables más relacionadas
corrplot.mixed(cor(numeric_vars[, c("Sale_Price", head(cor_with_target$Variable, 10))], 
                  use = "complete.obs"),
               upper = "circle",
               lower.col = "black",
               number.cex = 0.7,
               tl.cex = 0.7,
               tl.pos = "lt",
               title = "Matriz de correlación - Top 10 variables")
```

#### Relaciones bivariadas con las variables más correlacionadas

```{r top_correlations}
# Función para crear scatter plots con línea de tendencia
plot_scatter <- function(data, x_var, y_var = "Sale_Price") {
  data %>%
    ggplot(aes(x = !!sym(x_var), y = !!sym(y_var))) +
    geom_point(alpha = 0.5, color = "steelblue") +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    scale_y_continuous(labels = scales::dollar) +
    labs(title = paste("Relación entre", x_var, "y Sale_Price"),
         x = x_var,
         y = "Precio de Venta (USD)") +
    theme(plot.title = element_text(size = 10, hjust = 0.5))
}

# Variables numéricas más correlacionadas (excluyendo las que tienen muchos valores únicos)
top_numeric <- cor_with_target %>%
  filter(!Variable %in% c("Id", "Mo_Sold", "Year_Sold", "Garage_Yr_Blt")) %>%
  head(6) %>%
  pull(Variable)

# Crear scatter plots
scatter_plots <- map(top_numeric, ~plot_scatter(ames_data, .x))

# Mostrar gráficos
wrap_plots(scatter_plots, ncol = 2) + 
  plot_annotation(title = 'Relación entre las variables numéricas más correlacionadas y Sale_Price',
                  theme = theme(plot.title = element_text(hjust = 0.5, size = 12)))
```

### Variables categóricas

#### Análisis de variables categóricas importantes

```{r categorical_analysis}
#| eval: false
# Función para graficar variables categóricas vs Sale_Price
plot_cat_var <- function(data, var_name, y_var = "Sale_Price") {
  data %>%
    ggplot(aes(x = reorder(!!sym(var_name), !!sym(y_var), FUN = median, na.rm = TRUE), 
               y = !!sym(y_var))) +
    geom_boxplot(fill = "steelblue", alpha = 0.7) +
    stat_summary(fun = median, geom = "point", color = "red", size = 2) +
    scale_y_continuous(labels = scales::dollar) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
          plot.title = element_text(size = 10, hjust = 0.5)) +
    labs(title = paste("Distribución de", y_var, "por", var_name),
         x = var_name,
         y = y_var)
}

# Variables categóricas relevantes basadas en conocimiento de dominio
cat_vars <- c("Neighborhood", "Overall_Cond", "Kitchen_AbvGr", "Garage_Type", 
              "Heating_QC", "Foundation", "Bsmt_Cond")

# Crear gráficos
cat_plots <- map(cat_vars, ~plot_cat_var(ames_data, .x))

# Mostrar gráficos
wrap_plots(cat_plots, ncol = 2) + 
  plot_annotation(title = 'Distribución de Sale_Price por variables categóricas',
                  theme = theme(plot.title = element_text(hjust = 0.5, size = 14)))
```

## Análisis de valores faltantes y atípicos

Este análisis se encuentra integrado dentro de la sección **"Paneo Inicial y Diagnóstico de Calidad"**, donde se abordaron tanto los `NA` explícitos como las ausencias estructurales codificadas (e.g. `"None"`, `0`).

## Conclusiones y recomendaciones para el modelado

### Hallazgos principales

-   **Variable respuesta (Sale_Price)**:
    -   Distribución asimétrica a la derecha, con una cola larga hacia valores altos
    -   Coeficiente de variación del 44% indica una variabilidad moderada en los precios
    -   La transformación logarítmica mejora significativamente la normalidad de la distribución
-   **Variables numéricas más relevantes**:
    -   `Overall_Cond`, `Gr_Liv_Area`, `Garage_Cars`, `Garage_Area` y `Total_Bsmt_SF` muestran las correlaciones más fuertes con `Sale_Price`
    -   Se observan relaciones aproximadamente lineales con la variable respuesta
-   **Variables categóricas importantes**:
    -   `Neighborhood` muestra una gran variabilidad en los precios entre barrios
    -   `Overall_Cond` y tienen una fuerte relación con el precio de venta
    -   La calidad de los materiales y el acabado (`Exter_Qual`, `Bsmt_Qual`) también son predictores importantes
-   **Valores faltantes**:
    -   Varias variables tienen valores faltantes que deberán ser manejados
    -   Algunas variables como `Pool_QC`, `Misc_Feature` y `Alley` tienen una alta proporción de valores faltantes
-   **Valores atípicos**:
    -   Se identificaron XX valores atípicos en `Sale_Price` (aproximadamente YY% de los datos)
    -   Estos valores podrían ser casas de lujo o errores de medición

### Recomendaciones de preprocesamiento

> Todas las acciones indicadas aquí deben implementarse en la *recipe* preliminar o en pasos de ingeniería previos al ajuste de modelos en `HW2.qmd`.

#### Conversión de variables discretas a factores

| Variable       | Cardinalidad | Acción recomendada        | Comentario           |
|------------------|------------------|-------------------|------------------|
| Bsmt_Half_Bath | 3            | `factor(ordered = TRUE)`  | ordinal (0–2)        |
| Half_Bath      | 3            | `factor(ordered = TRUE)`  | ordinal (0–2)        |
| Bsmt_Full_Bath | 4            | `factor(ordered = TRUE)`  | ordinal (0–3)        |
| Kitchen_AbvGr  | 4            | `factor()`                | recuento discreto    |
| Full_Bath      | 5            | `factor(ordered = TRUE)`  |                      |
| Fireplaces     | 5            | `factor()`                | muchos ceros         |
| Year_Sold      | 5            | `factor(ordered = TRUE)`  | efecto temporal      |
| Garage_Cars    | 6            | `factor(ordered = TRUE)`  | 0–5 autos            |
| BsmtFin_SF_1   | 8            | *depende del modelo*      | revisar linealidad   |
| Bedroom_AbvGr  | 8            | *factor* **o** numérica   | distribución sesgada |
| Mo_Sold        | 12           | `factor(ordered = TRUE)`  | estacionalidad       |
| TotRms_AbvGrd  | 14           | *factor* **si** no lineal | revisión visual      |

#### Reagrupación de niveles en categóricas

-   **Alta cardinalidad**
    -   `Neighborhood` (28 niveles) → reagrupar niveles \< 1 % en “Otros”.\
    -   `Exterior_1st`/`Exterior_2nd` (16 niveles) → agrupar por material: `Vinyl`, `Wood`, `Brick`, `Otros`.
-   **Categorías infrecuentes**
    -   Ej.: `Landmark` (`Neighborhood`), `VWD` (`Sale_Type`) ⇒ “Other”.
-   **Variables binarias o quasi-binarias**
    -   `Central_Air`, `Street`, `Utilities`, `Pool_QC`, `Alley`, `Fence`, `Paved_Drive` ⇒ recodificar en lógicos `0/1`.
-   **Agrupaciones por dominio**
    -   `MS_SubClass` → `OneStory` / `TwoStory` / `SplitLevel`.\
    -   `House_Style` → `One_Story` / `Two_Story` / `Otros`.

#### Ingeniería de variables y transformaciones

| Variable (o grupo) | Problema detectado | Acción recomendada |
|------------------------|------------------------|------------------------|
| Lot_Frontage | ceros indican NA | reemplazar **0 → NA** + imputación KNN por `Neighborhood` |
| Garage_Area / Garage_Cars | muchos ceros (sin garaje) | crear `has_garage = Garage_Cars > 0`; `log1p(Garage_Area)` solo si `has_garage` |
| Total_Bsmt_SF | ausencia de sótano | `has_basement`, `log1p(Total_Bsmt_SF)` condicional |
| Mas_Vnr_Area | ceros estructurales | `has_veneer`, `log1p(Mas_Vnr_Area)` condicional; imputar `NA` donde `Mas_Vnr_Type == "None"` |
| Pool_Area | 99 % ceros | `has_pool`, `log1p(Pool_Area)` condicional |
| Sale_Price | asimetría + heteroscedasticidad | `step_log(all_outcomes())` |

Además se sugiere crear `Total_SF = First_Flr_SF + Second_Flr_SF + Total_Bsmt_SF` y `Age = Year_Sold – Year_Built`; ambas mostraron mayor señal que sus componentes aislados.

#### Tabla resumen final

```{r tbl_preproc_summary}
library(tibble)
library(dplyr)

preproc_tbl <- tribble(
  ~Variable,        ~Problema,                              ~Accion,
  "Lot_Frontage",   "Ceros como NA",                        "Imputar por barrio + step_knnimpute()",
  "Garage_Area",    "Muchos ceros",                         "log1p + interacción con has_garage",
  "Garage_Cars",    "Ordinal discreta",                     "factor(ordered = TRUE)",
  "Total_Bsmt_SF",  "Ausencia estructural",                 "has_basement + log1p condicional",
  "Mas_Vnr_Area",   "Ceros estructurales",                  "has_veneer + log1p condicional",
  "Pool_Area",      "Alta sparsidad",                       "has_pool + log1p condicional",
  "Neighborhood",   "Alta cardinalidad",                    "Reagrupar niveles raros (<1 %)",
  "Exterior_1st/2nd","Alta cardinalidad",                   "Agrupar por material",
  "Binarias (varias)", "Un nivel ≥90 %",                   "Recodificar a lógico 0/1",
  "Sale_Price",     "Asimetría derecha",                    "step_log(all_outcomes())",
  "Total_SF",       "No existe",                            "Crear feature derivada",
  "Age",            "No existe",                            "Crear feature derivada"
)

knitr::kable(preproc_tbl, caption = "Síntesis de problemas y acciones de preprocesamiento")
```

```{r}
sessionInfo()
```