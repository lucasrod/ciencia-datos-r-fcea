---
title: "Análisis Exploratorio: Conjunto Ames Housing"
subtitle: "Análisis para modelo de regresión con Sale_Price como variable respuesta"
format:
  html:
    self-contained: true
    toc: true
    toc-depth: 3
    code-fold: false
    code-tools: true
    code-summary: "Mostrar código"
execute:
  echo:    true
  warning: true
  message: false
editor: visual
---

```{r setup, message=FALSE}
# Cargar paquetes necesarios
library(tidyverse)
library(tidymodels) # ML
library(modeldata)  # Conjunto Ames housing
library(skimr)      # Análisis descriptivo
library(corrplot)   # Para matrices de correlación
library(GGally)     # Para pair plots avanzados
library(patchwork)  # Para combinar gráficos
library(ggthemes)   # Temas para ggplot2
library(e1071)      # Para asimetría y curtosis
library(robustbase) # Para medcouple: estadístico no paramétrico y robusto que mide la asimetría del "cuerpo central" de la distribución, sin verse afectado por outliers

# Reproducibilidad
set.seed(42)

# Configuración general
theme_set(theme_minimal())
options(dplyr.summarise.inform = FALSE)
```

# Análisis Exploratorio: Conjunto Ames Housing

## Resumen

Este análisis exploratorio tiene como objetivo complementar el trabajo realizado en `HW2.qmd`, proporcionando una caracterización del conjunto de datos `ames` antes de aplicar modelos supervisados. Se identifican patrones relevantes en la variable respuesta `Sale_Price`, se evalúan relaciones clave con las variables predictoras y se diagnostica la calidad general de los datos.

A continuación se sintetizan los principales hallazgos:

-   **Distribución de la variable objetivo (`Sale_Price`)**: Presenta una cola larga a la derecha, lo que sugiere que unas pocas viviendas tienen precios significativamente más altos que la mayoría. Esta observación, consistente con la exploración hecha en Kaggle, motiva el uso de transformaciones como `log(Sale_Price)` para estabilizar la varianza y mejorar la aproximación a la normalidad antes de aplicar modelos lineales.

-   **Estadísticos claves de `Sale_Price`**:

    -   Mediana: `XX`
    -   Media: `XX`
    -   Coeficiente de variación (CV): `XX%`
    -   Asimetría: `XX`
    -   Curtosis: `XX`

-   **Valores atípicos (outliers)**:

    -   Se detectaron `XX` observaciones (≈ `XX%`) fuera del rango intercuartílico.
    -   Se recomienda evaluar su impacto durante la validación del modelo.

-   **Calidad general del conjunto**:

    -   Total de observaciones: `2,930`
    -   Total de variables: `74`
    -   Variables con valores faltantes: `X` (ej. `Lot_Frontage`, `Alley`, etc.)
    -   No se detectan filas duplicadas por ID, aunque algunas variables presentan codificación especial de ausencia (ceros como "No aplica").

-   **Variables predictoras destacadas**:

    -   Las variables numéricas más correlacionadas con `Sale_Price` son: `Gr_Liv_Area`, `Garage_Area`, `Total_Bsmt_SF`, entre otras.
    -   Se observa colinealidad entre ciertos predictores relacionados con superficie.

-   **Sugerencias para el modelado**:

    -   Transformar `Sale_Price` mediante `log()` para mejorar los supuestos de normalidad.
    -   Evaluar interacciones no lineales y colinealidad entre variables.
    -   Considerar ingeniería de características que reflejen combinaciones relevantes (ej. superficie total habitable).

Este informe sirve como insumo previo para diseñar estrategias de preprocesamiento y selección de variables en el modelado predictivo.

## Paneo Inicial y Diagnóstico de Calidad

Realizamos un diagnóstico inicial del conjunto de datos `ames` cargado desde el paquete `{modeldata}`. Exploraremos su estructura, tipos de variables, codificaciones especiales, presencia de valores faltantes (*missing values*), ausencia estructural y duplicados.

```{r load_data}
# Cargar el conjunto ames
data(ames)
ames_data <- as_tibble(ames)
```

### Estructura

```{r glimpse}
glimpse(ames_data)
```

### Análisis descriptivo univariado

Diferenciamos entre variables numéricas y categóricas, y para cada tipo se presentan estadísticos de resumen, distribución, y niveles o codificaciones relevantes, útil para detectar problemas tempranos.

#### Clases de variables

Este análisis se desarrolla en R base + tidyverse, que emplean el sistema de clases **S3**. Durante este informe nos referiremos indistinguiblemente a los tipos de variables como a las clases. Aunque especificamente, usaremos `class()` para obtener las clases de variables que son un *tipo semántico* y `typeof()` para obtener el tipo de dato de R que es un *tipo primitivo*.

```{r class_types}
# Conteo de clases
ames_data %>%
  summarise(across(everything(), class)) %>%
  pivot_longer(cols = everything(), names_to = "n_variables", values_to = "class") %>%
  count(class, name = "n_variables") %>%
  knitr::kable(caption = "Distribución de clases de variables")
```

> **Notas**:
>
> Las clases se asignan automáticamente por R al importar los datos.
>
> Si consultamos el tipo primitivo que informa `typeof()`:
>
> -   Los vectores de clase `numeric` se almacenan como `"double"`
> -   Los vectores de clase `factor` se almacenan como `"integer"`.

##### Clase Factor

Las clases factor son variables categóricas codificadas o enumeradas como enteros con sus niveles asociados.

##### Clases Numéricas

Identificamos las variables numéricas por su clase en R (`integer` o `numeric`) y por su naturaleza semántica como discretas (si todos sus valores son enteros) o continuas (si contienen decimales). Esta clasificación no siempre coincide con el tipo primitivo de dato (`double` o `integer`) asignado automáticamente por el parser de R.

A su vez, calculamos la cardinalidad de cada variable, es decir, la cantidad de valores únicos observados. Este número resulta fundamental para distinguir entre variables que podrían recodificarse como factores (baja cardinalidad discreta) y aquellas que deben tratarse como numéricas en sentido estricto.

```{r}
num_vars <- ames_data %>% select(where(is.numeric))

numeric_classification <- tibble(
  variable    = names(num_vars),
  clase       = map_chr(variable, ~ class(ames_data[[.x]])[1]),
  is_discrete = map_lgl(variable, ~ all(ames_data[[.x]] == floor(ames_data[[.x]]), na.rm = TRUE))
) %>%
  mutate(
    tipo        = if_else(is_discrete, "Discreta", "Continua"),
    cardinalidad = map_int(variable, ~ n_distinct(ames_data[[.x]], na.rm = TRUE))
  ) %>%
  select(variable, clase, tipo, cardinalidad)

knitr::kable(
  numeric_classification %>% arrange(tipo, cardinalidad),
  caption = "Clasificación semántica de variables numéricas con cardinalidad"
)
```

> Nota: Observamos que variables como `Garage_Cars`, `Bsmt_Half_Bath` y `Bsmt_Full_Bath` son claramente numéricas discretas, pero fueron importadas como `numeric` (double) en vez de `integer`, a pesar de no tener decimales. Esta inconsistencia no afecta los cálculos pero sí debe considerarse al preparar modelos, ya que puede justificar transformar algunas de estas variables a `factor` u `ordered`.
>
> La lógica y criterios para convertir las variables numéricas discretas a factores (incluyendo la tabla de cardinalidades y las justificaciones) se han llevado a la sección **Recomendaciones de preprocesamiento** bajo el subtítulo **Conversión de variables discretas a factores**, donde encontraremos el listado completo y la acción sugerida para cada variable.

#### Tipo de variable para el análisis

Factores vs numéricos.

```{r skim_types}
skim_summary <- skim(ames_data)
skim_summary %>%
  count(skim_type, name = "n_variables") %>%
  knitr::kable(caption = "Distribución de tipo de variables (skim_type)")
```

#### Variables categóricas

Mostramos la cantidad de categorías y las categorías más observadas de las variables de tipo factor:

```{r cat_skim_summary}
skim_summary %>%
  filter(skim_type == "factor") %>%
  arrange(desc(factor.n_unique)) %>%
  select(
    variable    = skim_variable,
    n_levels    = factor.n_unique,
    top_counts  = factor.top_counts,
  ) %>%
  knitr::kable(
    caption = "Variables categóricas: niveles y counts principales"
  )
```

```{r cat_levels_distribution}

# Cardinalidad de cada factor desde skim_summary
cardinality <- skim_summary %>%
  filter(skim_type == "factor") %>%
  select(
    variable = skim_variable,
    n_levels = factor.n_unique
  )

# Conteo y proporciones por nivel
factor_vars <- cardinality$variable

prop_cat <- map_dfr(factor_vars, function(var) {
  ames_data %>%
    count(level = .data[[var]]) %>%
    mutate(
      variable = var,
      prop     = percent(n / sum(n), accuracy = 0.1)
    )
})

# Unir cardinalidad ordenando por n_levels (desc) y luego por n (desc)
prop_cat %>%
  left_join(cardinality, by = "variable") %>%
  arrange(
    desc(n_levels),  # se usa para ordenar, pero no se mostrará
    variable,
    desc(n)
  ) %>%
  select(variable, level, n, prop) %>%  # acá ya no incluimos n_levels
  knitr::kable(
    caption = "Distribución de niveles de variables categóricas"
  )
```

#### Variables numéricas

Calculamos medidas de tendencia central, posición, dispersión y dirección de asimetría (`media - mediana`):

```{r num_skim_summary}
skim_summary %>%
  filter(skim_type == "numeric") %>%
  transmute(
    variable = skim_variable,
    mean     = numeric.mean,
    sd       = numeric.sd,
    rel_skew = abs(numeric.mean - numeric.p50) / numeric.sd, # asimetría relativa a la dispersión
    asimetría = case_when(
      is.na(rel_skew)             ~ "indefinida",
      rel_skew < 0.1              ~ "Aprox. simétrica",
      numeric.mean > numeric.p50  ~ "Positiva",
      TRUE                        ~ "Negativa"
    ),
    histograma = numeric.hist,
    p0       = numeric.p0,
    p25      = numeric.p25,
    median   = numeric.p50,
    p75      = numeric.p75,
    p100     = numeric.p100
  ) %>%
  knitr::kable(
    digits = 2,
    caption = "Variables numéricas"
  )
```

> Nota: `rel_skew` es una aproximación útil para comparar diferencias relativas entre media y mediana entre distribuciones con escalas o unidades distintas. Sin embargo, **no siempre refleja adecuadamente la estructura de la distribución**. Por ejemplo:
>
> -   En `Lot_Area`, el valor de `rel_skew` es bajo a pesar de una asimetría real muy alta, ya que **la alta desviación estándar atenúa el impacto de colas extremas**.
> -   En `Kitchen_AbvGr`, la aparente simetría se debe a un **soporte discreto y reducido** con una moda dominante, lo que mantiene la media y mediana cercanas aunque exista asimetría.
> -   En `BsmtFin_SF_1`, se observa lo opuesto: la diferencia entre media y mediana parece indicar asimetría, pero se debe a **modas discretas separadas** dentro de una distribución que en realidad tiene colas relativamente simétricas.
>
> Por ello, se complementa el análisis con el coeficiente de asimetría (`skewness`) y otras métricas robustas.

```{r eval = FALSE}
skim_summary %>% rowwise() %>% mutate(x = list(ames_data[[skim_variable]])) %>% glimpse()
```

```{r extended_numeric_eda}
# Variables numéricas con EDA extendido
numeric_eda <- skim_summary %>%
  filter(skim_type == "numeric") %>%
  # Para poder usar e1071 necesitamos extraer cada vector numérico de las variables
  rowwise() %>%
  mutate(
    x = list(ames_data[[skim_variable]]), # vector original de cada variable
    cv = numeric.sd / numeric.mean,       # coef. de variación
    iqr = numeric.p75 - numeric.p25,      # rango IQ
    skewness = skewness(x),               # asimetría
    medcouple = mc(x,doScale = TRUE), # asimetría robusta
    kurtosis = kurtosis(x),               # curtosis
    prop_outliers = if_else(iqr == 0, NA_real_,
                        mean(x < (numeric.p25 - 1.5*iqr) |
                        x > (numeric.p75 + 1.5*iqr), 
                        na.rm = TRUE)), # outliers regla Tukey
    transform_rec = case_when(
      skewness < 0 ~ "ninguna: asimetría negativa",
      !all(x >= 0, na.rm = TRUE) ~ "ninguna: valores negativos",
      all(x > 0,  na.rm = TRUE) & skewness > 1.5 ~ "log",
      all(x > 0,  na.rm = TRUE) & skewness > 0.5 ~ "Box-Cox (evaluar)",
      all(x >= 0, na.rm = TRUE) & skewness > 0.5 ~ "log(x+1) o sqrt: contiene ceros",
      TRUE            ~ "ninguna"
    )
  ) %>%
  ungroup() %>%
  transmute(
    variable        = skim_variable,
    mean            = numeric.mean,
    sd              = numeric.sd,
    cv,
    skewness        = round(skewness, 2),
    medcouple       = round(medcouple, 2),
    kurtosis        = round(kurtosis, 2),
    pct_outliers    = percent(prop_outliers, accuracy = 0.1),
    iqr,
    histograma      = numeric.hist,
    transform_rec   = transform_rec
  )

  knitr::kable(
    numeric_eda,
    digits = 2,
    caption = "Análisis extendido de variables numéricas"
  )

```

> **Nota sobre las medidas de asimetría:** En este análisis se reportan dos métricas complementarias para evaluar la asimetría de las variables numéricas:
>
> -   `skewness` corresponde al coeficiente de asimetría muestral ($g_1$), una medida **paramétrica** que mide la forma de la distribución en función del sesgo respecto a la media (mediante el tercer momento central muestral). Es sensible a valores atípicos (*outliers*) y capta la **asimetría en las colas**.
> -   `medcouple`: es un **estadístico no paramétrico y robusto** que mide la asimetría del “cuerpo central" de la distribución, sin verse afectado por outliers.
>
> Dado que ambas métricas responden a diferentes aspectos de la forma de la distribución, pueden arrojar resultados aparentemente contradictorios:
>
> -   En variables con muchos ceros y algunos valores extremos altos (como `Pool_Area` o `Misc_Val`), el `medcouple` puede ser **negativo** (indicando que la masa principal está a la derecha), mientras que el `skewness` será **positivo** por la presencia de colas largas hacia la derecha.
>
> -   En otros casos, como `Kitchen_AbvGr`, aunque la media y la mediana están alineadas (dando idea de simetría), el `skewness` puede ser alto por la naturaleza discreta de la variable (muchos 1 y pocos valores mayores).
>
> Por ello, **es recomendable interpretar ambas medidas en conjunto**: `skewness` capta simetría global, incluyendo extremos, y `medcouple` resume la simetría de la parte mas densa de la distribución. Usarlas juntas da una visión más completa sobre la simetría de cada variable.

### Calidad de Datos y Ausencia Estructural

El tratamiento de valores faltantes es una etapa clave del preprocesamiento en proyectos de datos, ya que afecta directamente las decisiones de modelado, la validez de los patrones descubiertos y la capacidad de generalización de los modelos. No todos los modelos toleran valores faltantes, y su presencia puede introducir sesgos o errores si no se trata de forma adecuada (transformaciones). Como veremos, este conjunto no contiene valores faltantes explícitos, codificaciones que indican ausencia estructural, con el objetivo de tomar decisiones informadas para su tratamiento posterior.

Falta presentar resultados esperados a partir de la literatura relevante existente (Paper "Ames, Iowa: Alternative to the Boston Housing Data" y Kaggle notebooks) y contrastar resultados.

En esta sección abordamos:

-   Valores faltantes explícitos (`NA`)
-   Codificaciones especiales como `"None"`, `"No_"`, y ceros estructurales en variables numéricas
-   Ausencia estructural implícita a partir del contexto de la variable

Además, se documentan decisiones preliminares sobre imputación, transformación o recodificación para trazabilidad futura.

#### Valores faltantes explícitos (*missing values*)

```{r missing_values}
# Resumen de NAs
n_obs <- nrow(ames_data)
na_summary <- ames_data %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "n_na") %>%
  filter(n_na > 0) %>%
  mutate(pct = round(100 * n_na / n_obs, 2)) %>%
  arrange(desc(pct))

# Tabla vacía
# knitr::kable(na_summary, caption = "Variables con valores faltantes")
cat("Número de variables con NA:", nrow(na_summary), "\n")
```

> No se detectan *missing values* explícitos en el conjunto, lo que evita imputaciones tradicionales y nos lleva a las codificaciones especiales.

#### Variables categóricas: codificaciones especiales

Para un listado exhaustivo de todos los niveles de las variables categóricas, véase la sección "Variables categóricas" del análisis descriptivo univariado.

##### Codificaciones de ausencia

Las variables categóricas que indican ausencia estructural son aquellas que el data entry representa la ausencia de la característica usando strings como "None" o "No\_\*".

```{r}
# Niveles que indican ausencia
none_levels <- c("None", "No_Alley_Access", "No_Pool", "No_Fence", "No_Garage", "No_Basement")

ames_data %>%
  select(where(is.factor)) %>%
  summarise(across(everything(), ~ sum(. %in% none_levels))) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "n_none") %>%
  filter(n_none > 0) %>%
  mutate(percent = percent(n_none / n_obs, accuracy = 0.1)) %>%
  arrange(desc(n_none/ n_obs)) %>%
  select(-n_none) %>%
  knitr::kable(caption = "Variables categóricas con niveles que indican ausencia estructural")
```

> Todos los lineamientos relativos a la consolidación de niveles en variables categóricas (alta cardinalidad, agrupación de niveles raros, binarización, etc.) se encuentran ahora en **Recomendaciones de preprocesamiento** dentro de la subsección **Reagrupación de niveles en categóricas**, con ejemplos y tablas que explicitan la estrategia de recodificación para cada caso.

#### Variables numéricas: ceros estructurales

Variables numéricas como `Garage_Area` o `MasVnr_Area` pueden contener ceros que no representan valores cuantitativos reales, sino ausencia de la característica (p.ej., `Mas_Vnr_Area = 0` cuando `Mas_Vnr_Type == "None"`). Este detalle también se resalta en notebooks de Kaggle, donde se señala que “el valor 0 puede estar indicando que el criterio no aplicaba”. Prestar especial atención al imputar o escalar estos ceros.

Listamos la frecuencia de ceros estructurales en variables numéricas

```{r}
# Porcentaje de observaciones `0` en variables numéricas
ames_data %>%
  select(where(is.numeric)) %>%
  summarise(across(everything(), ~ mean(. == 0, na.rm = TRUE))) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "zeros_prop") %>%
  filter(zeros_prop > 0) %>%
  mutate(pct_zeros = percent(zeros_prop, accuracy = 0.1)) %>%
  arrange(desc(zeros_prop)) %>%
  select(-zeros_prop) %>%
  knitr::kable(caption = "Proporción de ceros estructurales en variables numéricas")
```

##### Mapeo de variables y métricas asociadas

Exploramos la relación entre variables categóricas y numéricas que pueden tener un comportamiento estructural similar. Se mapean pares de variables categóricas (`cat_var`) y numéricas (`num_var`) relacionadas, donde el valor cero en la variable numérica puede indicar la ausencia de la característica descrita por la variable categórica.

```{r}
pares <- list(
  c("Garage_Type",     "Garage_Area"),
  c("Garage_Cond",     "Garage_Area"),
  c("Bsmt_Cond",       "Total_Bsmt_SF"), 
  c("Bsmt_Exposure",   "Total_Bsmt_SF"), 
  c("Pool_QC",         "Pool_Area"),
  c("Mas_Vnr_Type",     "Mas_Vnr_Area"),
  c("Misc_Feature",    "Misc_Val")
)

# Número total de observaciones
n_obs <- nrow(ames_data)

# Función que, dado un par (cat_var, num_var), devuelve un tibble con métricas
resumen_pareado <- function(par) {
  cat_var <- par[1]
  num_var <- par[2]

  # Filtrar none / cero
  df <- ames_data %>%
    mutate(
      is_none = .data[[cat_var]] %in% none_levels,
      is_zero = .data[[num_var]] == 0
    )

  n_none        <- sum(df$is_none,    na.rm = TRUE)
  n_zero        <- sum(df$is_zero,    na.rm = TRUE)
  n_none_zero   <- sum(df$is_none & df$is_zero, na.rm = TRUE)

  tibble(
    cat_var              = cat_var,
    num_var              = num_var,
    n_none               = n_none,
    pct_none             = percent(n_none / n_obs, accuracy = 0.1),
    n_zero               = n_zero,
    pct_zero             = percent(n_zero / n_obs, accuracy = 0.1),
    n_none_zero          = n_none_zero,
    pct_zero_given_none  = if (n_none>0) percent(n_none_zero / n_none, accuracy = 0.1) else NA_real_,
    pct_none_given_zero  = if (n_zero>0) percent(n_none_zero / n_zero, accuracy = 0.1) else NA_real_
  )
}

# Mapeamos y combinamos en un solo data.frame
tabla_ausencia <- map_dfr(pares, resumen_pareado)

knitr::kable(
  tabla_ausencia,
  caption = "Métricas de ausencia estructural por par (None vs 0)",
  col.names = c(
    "Var. Categ.", "Var. Num.",
    "count None", "pct None",
    "count 0",    "pct 0",
    "count None∧0",
    "pct 0|None", "pct None|0"
  )
)
```

> Esta tabla valida la consistencia interna y guía la ingeniería de variables, sobretodo en variables como `Garage_Area`, `Total_Bsmt_SF` y `Mas_Vnr_Area`que estan altamente correlacionadas con `Sale_Price`.
>
> Las recomendaciones puntuales de ingeniería (creación de indicadores, transformaciones logarítmicas, interacciones y reemplazo de ceros por `NA`) se han unificado en **Recomendaciones de preprocesamiento** dentro de la sección **Ingeniería de variables y transformaciones**, acompañadas por una tabla final que resume problemas detectados y acciones recomendadas.

#### Duplicados

No existe variable `Id` en el conjunto, por lo que no se puede validar unicidad de filas por identificador. Validaremos unicidad de filas por fila completa.

```{r duplicates}
# Validar unicidad de Id si existiera o por fila completa
n_duplicadas <- ames_data %>% duplicated() %>% sum()
cat("Número de filas duplicadas:", n_duplicadas, "\n")
```

> No se detectan filas duplicadas exactas.

## Análisis de la variable respuesta: Sale_Price

### Resumen estadístico

```{r target_summary}
# Resumen estadístico de Sale_Price
summary(ames_data$Sale_Price)

# Coeficiente de variación
cv_sale_price <- sd(ames_data$Sale_Price, na.rm = TRUE) / mean(ames_data$Sale_Price, na.rm = TRUE) * 100
cv_sale_price <- round(cv_sale_price, 2)

cat("Coeficiente de variación de Sale_Price:", cv_sale_price, "%\n")

skewness_value <- skewness(ames_data$Sale_Price, na.rm = TRUE)
kurtosis_value <- kurtosis(ames_data$Sale_Price, na.rm = TRUE)

cat("Asimetría:", round(skewness_value, 2), "\n")
cat("Curtosis:", round(kurtosis_value, 2), "\n")
```

### Visualización de la distribución

```{r target_distribution}
# Histograma con curva de densidad
p1 <- ames_data %>%
  ggplot(aes(x = Sale_Price)) +
  geom_histogram(aes(y = after_stat(density)), 
                 bins = 50, 
                 fill = "steelblue", 
                 color = "white", 
                 alpha = 0.8) +
  geom_density(color = "red", linewidth = 1) +
  scale_x_continuous(labels = scales::dollar) +
  labs(title = "Distribución de Precios de Venta",
       x = "Precio de Venta (USD)",
       y = "Densidad") +
  theme(plot.title = element_text(hjust = 0.5))

# QQ-plot para normalidad
p2 <- ggplot(ames_data, aes(sample = Sale_Price)) +
  stat_qq(color = "steelblue") +
  stat_qq_line(color = "red") +
  labs(title = "QQ-Plot de Normalidad",
       x = "Cuantiles Teóricos",
       y = "Cuantiles Muestrales") +
  theme(plot.title = element_text(hjust = 0.5))

# Boxplot para identificar valores atípicos
p3 <- ames_data %>%
  ggplot(aes(y = Sale_Price)) +
  geom_boxplot(fill = "steelblue", alpha = 0.7) +
  scale_y_continuous(labels = scales::dollar) +
  labs(title = "Boxplot de Precios de Venta",
       y = "Precio de Venta (USD)") +
  theme(plot.title = element_text(hjust = 0.5))

# Mostrar gráficos
(p1 + p2) / p3 + plot_layout(heights = c(2, 1))
```

### Transformación logarítmica

```{r log_transform}
# Aplicar transformación logarítmica
ames_data <- ames_data %>%
  mutate(log_Sale_Price = log(Sale_Price))

# Visualizar distribución transformada
p4 <- ames_data %>%
  ggplot(aes(x = log_Sale_Price)) +
  geom_histogram(aes(y = after_stat(density)), 
                 bins = 50, 
                 fill = "steelblue", 
                 color = "white", 
                 alpha = 0.8) +
  geom_density(color = "red", linewidth = 1) +
  labs(title = "Distribución de log(Sale_Price)",
       x = "log(Precio de Venta)",
       y = "Densidad") +
  theme(plot.title = element_text(hjust = 0.5))

# QQ-plot para normalidad de la variable transformada
p5 <- ggplot(ames_data, aes(sample = log_Sale_Price)) +
  stat_qq(color = "steelblue") +
  stat_qq_line(color = "red") +
  labs(title = "QQ-Plot de log(Sale_Price)",
       x = "Cuantiles Teóricos",
       y = "Cuantiles Muestrales") +
  theme(plot.title = element_text(hjust = 0.5))

# Mostrar gráficos transformados
p4 + p5
```

## Análisis de variables predictoras

### Variables numéricas

#### Correlación con variables numéricas

```{r numeric_correlation}
# Seleccionar solo variables numéricas
numeric_vars <- ames_data %>%
  select(where(is.numeric)) %>%
  select(-any_of("log_Sale_Price")) %>% # Excluimos la variable respuesta transformada
  select(-matches("^[A-Za-z]+\\.y\\.+[0-9]+\\.?[0-9]*$"))  # Eliminar columnas duplicadas

# Matriz de correlación
cor_matrix <- cor(numeric_vars, use = "complete.obs")

# Variables más correlacionadas con Sale_Price
cor_with_target <- cor_matrix[, "Sale_Price", drop = FALSE] %>%
  as.data.frame() %>%
  rownames_to_column("Variable") %>%
  arrange(desc(Sale_Price)) %>%
  filter(Variable != "Sale_Price")

# Mostrar las 15 variables más correlacionadas
head(cor_with_target, 15) %>% 
  knitr::kable(digits = 3, 
               col.names = c("Variable", "Correlación con Sale_Price"),
               caption = "Variables numéricas más correlacionadas con Sale_Price")

# Gráfico de correlación para las 10 variables más relacionadas
corrplot.mixed(cor(numeric_vars[, c("Sale_Price", head(cor_with_target$Variable, 10))], 
                  use = "complete.obs"),
               upper = "circle",
               lower.col = "black",
               number.cex = 0.7,
               tl.cex = 0.7,
               tl.pos = "lt",
               title = "Matriz de correlación - Top 10 variables")
```

#### Relaciones bivariadas con las variables más correlacionadas

```{r top_correlations}
# Función para crear scatter plots con línea de tendencia
plot_scatter <- function(data, x_var, y_var = "Sale_Price") {
  data %>%
    ggplot(aes(x = !!sym(x_var), y = !!sym(y_var))) +
    geom_point(alpha = 0.5, color = "steelblue") +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    scale_y_continuous(labels = scales::dollar) +
    labs(title = paste("Relación entre", x_var, "y Sale_Price"),
         x = x_var,
         y = "Precio de Venta (USD)") +
    theme(plot.title = element_text(size = 10, hjust = 0.5))
}

# Variables numéricas más correlacionadas (excluyendo las que tienen muchos valores únicos)
top_numeric <- cor_with_target %>%
  filter(!Variable %in% c("Id", "Mo_Sold", "Year_Sold", "Garage_Yr_Blt")) %>%
  head(6) %>%
  pull(Variable)

# Crear scatter plots
scatter_plots <- map(top_numeric, ~plot_scatter(ames_data, .x))

# Mostrar gráficos
wrap_plots(scatter_plots, ncol = 2) + 
  plot_annotation(title = 'Relación entre las variables numéricas más correlacionadas y Sale_Price',
                  theme = theme(plot.title = element_text(hjust = 0.5, size = 12)))
```

### Variables categóricas

#### Análisis de variables categóricas importantes

```{r categorical_analysis}
#| eval: false
# Función para graficar variables categóricas vs Sale_Price
plot_cat_var <- function(data, var_name, y_var = "Sale_Price") {
  data %>%
    ggplot(aes(x = reorder(!!sym(var_name), !!sym(y_var), FUN = median, na.rm = TRUE), 
               y = !!sym(y_var))) +
    geom_boxplot(fill = "steelblue", alpha = 0.7) +
    stat_summary(fun = median, geom = "point", color = "red", size = 2) +
    scale_y_continuous(labels = scales::dollar) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
          plot.title = element_text(size = 10, hjust = 0.5)) +
    labs(title = paste("Distribución de", y_var, "por", var_name),
         x = var_name,
         y = y_var)
}

# Variables categóricas relevantes basadas en conocimiento de dominio
cat_vars <- c("Neighborhood", "Overall_Cond", "Kitchen_AbvGr", "Garage_Type", 
              "Heating_QC", "Foundation", "Bsmt_Cond")

# Crear gráficos
cat_plots <- map(cat_vars, ~plot_cat_var(ames_data, .x))

# Mostrar gráficos
wrap_plots(cat_plots, ncol = 2) + 
  plot_annotation(title = 'Distribución de Sale_Price por variables categóricas',
                  theme = theme(plot.title = element_text(hjust = 0.5, size = 14)))
```

## Análisis de valores faltantes y atípicos

Este análisis se encuentra integrado dentro de la sección **"Paneo Inicial y Diagnóstico de Calidad"**, donde se abordaron tanto los `NA` explícitos como las ausencias estructurales codificadas (e.g. `"None"`, `0`).

## Conclusiones y recomendaciones para el modelado

### Hallazgos principales

-   **Variable respuesta (Sale_Price)**:
    -   Distribución asimétrica a la derecha, con una cola larga hacia valores altos
    -   Coeficiente de variación del XX% indica una variabilidad moderada en los precios
    -   La transformación logarítmica mejora significativamente la normalidad de la distribución
-   **Variables numéricas más relevantes**:
    -   `Overall_Qual`, `Gr_Liv_Area`, `Garage_Cars`, `Garage_Area` y `Total_Bsmt_SF` muestran las correlaciones más fuertes con `Sale_Price`
    -   Se observan relaciones aproximadamente lineales con la variable respuesta
-   **Variables categóricas importantes**:
    -   `Neighborhood` muestra una gran variabilidad en los precios entre barrios
    -   `Overall_Qual` y `Kitchen_Qual` tienen una fuerte relación con el precio de venta
    -   La calidad de los materiales y el acabado (`Exter_Qual`, `Bsmt_Qual`) también son predictores importantes
-   **Valores faltantes**:
    -   Varias variables tienen valores faltantes que deberán ser manejados
    -   Algunas variables como `Pool_QC`, `Misc_Feature` y `Alley` tienen una alta proporción de valores faltantes
-   **Valores atípicos**:
    -   Se identificaron XX valores atípicos en `Sale_Price` (aproximadamente YY% de los datos)
    -   Estos valores podrían ser casas de lujo o errores de medición

### Recomendaciones de preprocesamiento

> Todas las acciones indicadas aquí deben implementarse en la *recipe* preliminar o en pasos de ingeniería previos al ajuste de modelos en `HW2.qmd`.

#### Conversión de variables discretas a factores

| Variable       | Cardinalidad | Acción recomendada        | Comentario           |
|----------------|--------------|---------------------------|----------------------|
| Bsmt_Half_Bath |            3 | `factor(ordered = TRUE)`  | ordinal (0–2)        |
| Half_Bath      |            3 | `factor(ordered = TRUE)`  | ordinal (0–2)        |
| Bsmt_Full_Bath |            4 | `factor(ordered = TRUE)`  | ordinal (0–3)        |
| Kitchen_AbvGr  |            4 | `factor()`                | recuento discreto    |
| Full_Bath      |            5 | `factor(ordered = TRUE)`  |                      |
| Fireplaces     |            5 | `factor()`                | muchos ceros         |
| Year_Sold      |            5 | `factor(ordered = TRUE)`  | efecto temporal      |
| Garage_Cars    |            6 | `factor(ordered = TRUE)`  | 0–5 autos            |
| BsmtFin_SF_1   |            8 | *depende del modelo*      | revisar linealidad   |
| Bedroom_AbvGr  |            8 | *factor* **o** numérica   | distribución sesgada |
| Mo_Sold        |           12 | `factor(ordered = TRUE)`  | estacionalidad       |
| TotRms_AbvGrd  |           14 | *factor* **si** no lineal | revisión visual      |

#### Reagrupación de niveles en categóricas

-   **Alta cardinalidad**
    -   `Neighborhood` (28 niveles) → reagrupar niveles \< 1 % en “Otros”.\
    -   `Exterior_1st`/`Exterior_2nd` (16 niveles) → agrupar por material: `Vinyl`, `Wood`, `Brick`, `Otros`.
-   **Categorías infrecuentes**
    -   Ej.: `Landmark` (`Neighborhood`), `VWD` (`Sale_Type`) ⇒ “Other”.
-   **Variables binarias o quasi-binarias**
    -   `Central_Air`, `Street`, `Utilities`, `Pool_QC`, `Alley`, `Fence`, `Paved_Drive` ⇒ recodificar en lógicos `0/1`.
-   **Agrupaciones por dominio**
    -   `MS_SubClass` → `OneStory` / `TwoStory` / `SplitLevel`.\
    -   `House_Style` → `One_Story` / `Two_Story` / `Otros`.

#### Ingeniería de variables y transformaciones

| Variable (o grupo) | Problema detectado | Acción recomendada |
|------------------------|------------------------|------------------------|
| Lot_Frontage | ceros indican NA | reemplazar **0 → NA** + imputación KNN por `Neighborhood` |
| Garage_Area / Garage_Cars | muchos ceros (sin garaje) | crear `has_garage = Garage_Cars > 0`; `log1p(Garage_Area)` solo si `has_garage` |
| Total_Bsmt_SF | ausencia de sótano | `has_basement`, `log1p(Total_Bsmt_SF)` condicional |
| Mas_Vnr_Area | ceros estructurales | `has_veneer`, `log1p(Mas_Vnr_Area)` condicional; imputar `NA` donde `Mas_Vnr_Type == "None"` |
| Pool_Area | 99 % ceros | `has_pool`, `log1p(Pool_Area)` condicional |
| Sale_Price | asimetría + heteroscedasticidad | `step_log(all_outcomes())` |

Además se sugiere crear `Total_SF = First_Flr_SF + Second_Flr_SF + Total_Bsmt_SF` y `Age = Year_Sold – Year_Built`; ambas mostraron mayor señal que sus componentes aislados.

#### Tabla resumen final

```{r tbl_preproc_summary, echo=FALSE, message=FALSE}
library(tibble)
library(dplyr)

preproc_tbl <- tribble(
  ~Variable,        ~Problema,                              ~Accion,
  "Lot_Frontage",   "Ceros como NA",                        "Imputar por barrio + step_knnimpute()",
  "Garage_Area",    "Muchos ceros",                         "log1p + interacción con has_garage",
  "Garage_Cars",    "Ordinal discreta",                     "factor(ordered = TRUE)",
  "Total_Bsmt_SF",  "Ausencia estructural",                 "has_basement + log1p condicional",
  "Mas_Vnr_Area",   "Ceros estructurales",                  "has_veneer + log1p condicional",
  "Pool_Area",      "Alta sparsidad",                       "has_pool + log1p condicional",
  "Neighborhood",   "Alta cardinalidad",                    "Reagrupar niveles raros (<1 %)",
  "Exterior_1st/2nd","Alta cardinalidad",                   "Agrupar por material",
  "Binarias (varias)", "Un nivel ≥90 %",                   "Recodificar a lógico 0/1",
  "Sale_Price",     "Asimetría derecha",                    "step_log(all_outcomes())",
  "Total_SF",       "No existe",                            "Crear feature derivada",
  "Age",            "No existe",                            "Crear feature derivada"
)

knitr::kable(preproc_tbl, caption = "Síntesis de problemas y acciones de preprocesamiento")
```

```{r}
sessionInfo()
```