---
title: "Análisis Exploratorio: Conjunto Ames Housing"
subtitle: "Análisis para modelo de regresión con Sale_Price como variable respuesta"
format:
  html:
    self-contained: true
    toc: true
    toc-depth: 3
    code-fold: false
    code-tools: true
    code-summary: "Mostrar código"
execute:
  echo:    true
  warning: true
  message: false
editor: visual
---

```{r setup, message=FALSE}
# Cargar paquetes necesarios
library(tidyverse)
library(tidymodels) # ML
library(modeldata)  # Conjunto Ames housing
library(skimr)      # Análisis descriptivo
library(corrplot)   # Para matrices de correlación
library(GGally)     # Para pair plots avanzados
library(patchwork)  # Para combinar gráficos
library(ggthemes)   # Temas para ggplot2
library(e1071)      # Para asimetría y curtosis
library(robustbase) # Para medcouple: estadístico no paramétrico y robusto que mide la asimetría del "cuerpo central" de la distribución, sin verse afectado por outliers
library(naniar)     # Para visualización de valores faltantes

# Reproducibilidad
set.seed(42)

# Configuración general
theme_set(theme_minimal())
options(dplyr.summarise.inform = FALSE)
```

# Análisis Exploratorio: Conjunto Ames Housing

## Resumen

Este análisis exploratorio tiene como objetivo complementar el trabajo realizado en `HW2.qmd`, proporcionando una caracterización del conjunto de datos `ames` antes de aplicar modelos supervisados. Se identifican patrones relevantes en la variable respuesta `Sale_Price`, se evalúan relaciones clave con las variables predictoras y se diagnostica la calidad general de los datos.

A continuación se sintetizan los principales hallazgos:

-   **Distribución de la variable objetivo (`Sale_Price`)**: Presenta una cola larga a la derecha, lo que sugiere que unas pocas viviendas tienen precios significativamente más altos que la mayoría. Esta observación, consistente con la exploración hecha en Kaggle, motiva el uso de transformaciones como `log(Sale_Price)` para estabilizar la varianza y mejorar la aproximación a la normalidad antes de aplicar modelos lineales.

-   **Estadísticos claves de `Sale_Price`**:

    -   Mediana: `XX`
    -   Media: `XX`
    -   Coeficiente de variación (CV): `XX%`
    -   Asimetría: `XX`
    -   Curtosis: `XX`

-   **Valores atípicos (outliers)**:

    -   Se detectaron `XX` observaciones (≈ `XX%`) fuera del rango intercuartílico.
    -   Se recomienda evaluar su impacto durante la validación del modelo.

-   **Calidad general del conjunto**:

    -   Total de observaciones: `2,930`
    -   Total de variables: `74`
    -   Variables con valores faltantes: `X` (ej. `Lot_Frontage`, `Alley`, etc.)
    -   No se detectan filas duplicadas por ID, aunque algunas variables presentan codificación especial de ausencia (ceros como "No aplica").

-   **Variables predictoras destacadas**:

    -   Las variables numéricas más correlacionadas con `Sale_Price` son: `Gr_Liv_Area`, `Garage_Area`, `Total_Bsmt_SF`, entre otras.
    -   Se observa colinealidad entre ciertos predictores relacionados con superficie.

-   **Sugerencias para el modelado**:

    -   Transformar `Sale_Price` mediante `log()` para mejorar los supuestos de normalidad.
    -   Evaluar interacciones no lineales y colinealidad entre variables.
    -   Considerar ingeniería de características que reflejen combinaciones relevantes (ej. superficie total habitable).

Este informe sirve como insumo previo para diseñar estrategias de preprocesamiento y selección de variables en el modelado predictivo.

## Paneo Inicial y Diagnóstico de Calidad

Realizamos un diagnóstico inicial del conjunto de datos `ames` cargado desde el paquete `{modeldata}`. Exploraremos su estructura, tipos de variables, codificaciones especiales, presencia de valores faltantes (*missing values*), ausencia estructural y duplicados.

```{r load_data}
# Cargar el conjunto ames
data(ames)
ames_data <- as_tibble(ames)
```

### Estructura

```{r glimpse}
glimpse(ames_data)
```

### Análisis descriptivo univariado

Diferenciamos entre variables numéricas y categóricas, y para cada tipo se presentan estadísticos de resumen, distribución, y niveles o codificaciones relevantes, útil para detectar problemas tempranos.

#### Clases de variables

Este análisis se desarrolla en R base + tidyverse, que emplean el sistema de clases **S3**. Durante este informe nos referiremos indistinguiblemente a los tipos de variables como a las clases. Aunque especificamente, usaremos `class()` para obtener las clases de variables que son un *tipo semántico* y `typeof()` para obtener el tipo de dato de R que es un *tipo primitivo*.

```{r class_types}
# Conteo de clases
ames_data %>%
  summarise(across(everything(), class)) %>%
  pivot_longer(cols = everything(), names_to = "n_variables", values_to = "class") %>%
  count(class, name = "n_variables") %>%
  knitr::kable(caption = "Distribución de clases de variables")
```

> **Notas**:
>
> Las clases se asignan automáticamente por R al importar los datos.
>
> Si consultamos el tipo primitivo que informa `typeof()`:
>
> -   Los vectores de clase `numeric` se almacenan como `"double"`
> -   Los vectores de clase `factor` se almacenan como `"integer"`.

##### Clase Factor

Las clases factor son variables categóricas codificadas o enumeradas como enteros con sus niveles asociados.

##### Clases Numéricas

Identificamos las variables numéricas por su clase en R (`integer` o `numeric`) y por su naturaleza semántica como discretas (si todos sus valores son enteros) o continuas (si contienen decimales). Esta clasificación no siempre coincide con el tipo primitivo de dato (`double` o `integer`) asignado automáticamente por el parser de R.

A su vez, calculamos la cardinalidad de cada variable, es decir, la cantidad de valores únicos observados. Este número resulta fundamental para distinguir entre variables que podrían recodificarse como factores (baja cardinalidad discreta) y aquellas que deben tratarse como numéricas en sentido estricto.

```{r}
num_vars <- ames_data %>% select(where(is.numeric))

numeric_classification <- tibble(
  variable    = names(num_vars),
  clase       = map_chr(variable, ~ class(ames_data[[.x]])[1]),
  is_discrete = map_lgl(variable, ~ all(ames_data[[.x]] == floor(ames_data[[.x]]), na.rm = TRUE))
) %>%
  mutate(
    tipo        = if_else(is_discrete, "Discreta", "Continua"),
    cardinalidad = map_int(variable, ~ n_distinct(ames_data[[.x]], na.rm = TRUE))
  ) %>%
  select(variable, clase, tipo, cardinalidad)

knitr::kable(
  numeric_classification %>% arrange(tipo, cardinalidad),
  caption = "Clasificación semántica de variables numéricas con cardinalidad"
)
```

> Nota: Observamos que variables como `Garage_Cars`, `Bsmt_Half_Bath` y `Bsmt_Full_Bath` son claramente numéricas discretas, pero fueron importadas como `numeric` (double) en vez de `integer`, a pesar de no tener decimales. Esta inconsistencia no afecta los cálculos pero sí debe considerarse al preparar modelos, ya que puede justificar transformar algunas de estas variables a `factor` u `ordered`.

###### Conversión de variables discretas a factores

Una heurística ampliamente utilizada en análisis exploratorio y preprocesamiento de datos sugiere que las variables numéricas discretas con una cardinalidad baja (comúnmente ≤ 10 o 15) deberían considerarse candidatas para ser tratadas como factores, en lugar de variables numéricas continuas. Esta recomendación se basa en que dichas variables suelen representar:

* **Categorías codificadas numéricamente** (por ejemplo, cantidad de baños),
* **Conteos pequeños o acotados** (número de cocinas, chimeneas, etc.),
* **Escalas ordinales o temporales discretas** (mes, año de venta).

En nuestro caso, las siguientes variables cumplen con esta condición (cardinalidad ≤ 15) y son clasificadas como numéricas discretas:

| Variable         | Cardinalidad | Recomendación                            |
| ---------------- | ------------ | ---------------------------------------- |
| `Bsmt_Half_Bath` | 3            | ✅ Recontar o factorizar                  |
| `Half_Bath`      | 3            | ✅ Recontar o factorizar                  |
| `Bsmt_Full_Bath` | 4            | ✅ Recontar o factorizar                  |
| `Kitchen_AbvGr`  | 4            | ✅ Codifica cantidad fija                 |
| `Full_Bath`      | 5            | ✅ Categoría ordinal clara                |
| `Fireplaces`     | 5            | ✅ Recuento categórico                    |
| `Year_Sold`      | 5            | ✅ Variable temporal discreta             |
| `Garage_Cars`    | 6            | ✅ Cantidad ordinal limitada              |
| `BsmtFin_SF_1`   | 8            | ⚠️ Depende del modelo                    |
| `Bedroom_AbvGr`  | 8            | ⚠️ Puede ser ordinal o continua discreta |
| `Mo_Sold`        | 12           | ✅ Mes del año (ordinal)                  |
| `TotRms_AbvGrd`  | 14           | ⚠️ Revisar distribución                  |

En concreto se recomienda:

-   Para las variables con cardinalidad ≤ 6 (**especialmente `Bsmt_Half_Bath`, `Half_Bath`, `Kitchen_AbvGr`, `Garage_Cars` y `Fireplaces`**), se recomienda convertirlas a `factor()` o `ordered()` según su naturaleza, lo que puede mejorar la interpretabilidad de los modelos y reducir el riesgo de inferencias espurias al tratarlas como numéricas puras.
-   Para las variables de tiempo discreto, como `Year_Sold` y `Mo_Sold`, también deben considerarse factores ordenados si se planea modelar efectos estacionales o temporales.
-   En el caso de variables como `TotRms_AbvGrd` o `Bedroom_AbvGr`, inspeccionaremos su distribución: si la mayor parte del soporte está dominado por pocos valores comunes (ej. 5, 6, 7), y no se espera una relación estrictamente lineal con la variable de interés, puede justificarse también su recodificación.

#### Tipo de variable para el análisis

Factores vs numéricos.

```{r skim_types}
skim_summary <- skim(ames_data)
skim_summary %>%
  count(skim_type, name = "n_variables") %>%
  knitr::kable(caption = "Distribución de tipo de variables (skim_type)")
```

#### Variables categóricas

Mostramos la cantidad de categorías y las categorías más observadas de las variables de tipo factor:

```{r cat_skim_summary}
skim_summary %>%
  filter(skim_type == "factor") %>%
  arrange(desc(factor.n_unique)) %>%
  select(
    variable    = skim_variable,
    n_levels    = factor.n_unique,
    top_counts  = factor.top_counts,
  ) %>%
  knitr::kable(
    caption = "Variables categóricas: niveles y counts principales"
  )
```

```{r cat_levels_distribution}

# Cardinalidad de cada factor desde skim_summary
cardinality <- skim_summary %>%
  filter(skim_type == "factor") %>%
  select(
    variable = skim_variable,
    n_levels = factor.n_unique
  )

# Conteo y proporciones por nivel
factor_vars <- cardinality$variable

prop_cat <- map_dfr(factor_vars, function(var) {
  ames_data %>%
    count(level = .data[[var]]) %>%
    mutate(
      variable = var,
      prop     = percent(n / sum(n), accuracy = 0.1)
    )
})

# Unir cardinalidad ordenando por n_levels (desc) y luego por n (desc)
prop_cat %>%
  left_join(cardinality, by = "variable") %>%
  arrange(
    desc(n_levels),  # se usa para ordenar, pero no se mostrará
    variable,
    desc(n)
  ) %>%
  select(variable, level, n, prop) %>%  # acá ya no incluimos n_levels
  knitr::kable(
    caption = "Distribución de niveles de variables categóricas"
  )
```

#### Variables numéricas

Calculamos medidas de tendencia central, posición, dispersión y dirección de asimetría (`media - mediana`):

```{r num_skim_summary}
skim_summary %>%
  filter(skim_type == "numeric") %>%
  transmute(
    variable = skim_variable,
    mean     = numeric.mean,
    sd       = numeric.sd,
    rel_skew = abs(numeric.mean - numeric.p50) / numeric.sd, # asimetría relativa a la dispersión
    asimetría = case_when(
      is.na(rel_skew)             ~ "indefinida",
      rel_skew < 0.1              ~ "Aprox. simétrica",
      numeric.mean > numeric.p50  ~ "Positiva",
      TRUE                        ~ "Negativa"
    ),
    histograma = numeric.hist,
    p0       = numeric.p0,
    p25      = numeric.p25,
    median   = numeric.p50,
    p75      = numeric.p75,
    p100     = numeric.p100
  ) %>%
  knitr::kable(
    digits = 2,
    caption = "Variables numéricas"
  )
```

> Nota: `rel_skew` es una aproximación útil para comparar diferencias relativas entre media y mediana entre distribuciones con escalas o unidades distintas. Sin embargo, **no siempre refleja adecuadamente la estructura de la distribución**. Por ejemplo:
>
> -   En `Lot_Area`, el valor de `rel_skew` es bajo a pesar de una asimetría real muy alta, ya que **la alta desviación estándar atenúa el impacto de colas extremas**.
> -   En `Kitchen_AbvGr`, la aparente simetría se debe a un **soporte discreto y reducido** con una moda dominante, lo que mantiene la media y mediana cercanas aunque exista asimetría.
> -   En `BsmtFin_SF_1`, se observa lo opuesto: la diferencia entre media y mediana parece indicar asimetría, pero se debe a **modas discretas separadas** dentro de una distribución que en realidad tiene colas relativamente simétricas.
>
> Por ello, se complementa el análisis con el coeficiente de asimetría (`skewness`) y otras métricas robustas.

```{r eval = FALSE}
skim_summary %>% rowwise() %>% mutate(x = list(ames_data[[skim_variable]])) %>% glimpse()
```

```{r extended_numeric_eda}
# Variables numéricas con EDA extendido
numeric_eda <- skim_summary %>%
  filter(skim_type == "numeric") %>%
  # Para poder usar e1071 necesitamos extraer cada vector numérico de las variables
  rowwise() %>%
  mutate(
    x = list(ames_data[[skim_variable]]), # vector original de cada variable
    cv = numeric.sd / numeric.mean,       # coef. de variación
    iqr = numeric.p75 - numeric.p25,      # rango IQ
    skewness = skewness(x),               # asimetría
    medcouple = mc(x,doScale = TRUE), # asimetría robusta
    kurtosis = kurtosis(x),               # curtosis
    prop_outliers = if_else(iqr == 0, NA_real_,
                        mean(x < (numeric.p25 - 1.5*iqr) |
                        x > (numeric.p75 + 1.5*iqr), 
                        na.rm = TRUE)), # outliers regla Tukey
    transform_rec = case_when(
      skewness < 0 ~ "ninguna: asimetría negativa",
      !all(x >= 0, na.rm = TRUE) ~ "ninguna: valores negativos",
      all(x > 0,  na.rm = TRUE) & skewness > 1.5 ~ "log",
      all(x > 0,  na.rm = TRUE) & skewness > 0.5 ~ "Box-Cox (evaluar)",
      all(x >= 0, na.rm = TRUE) & skewness > 0.5 ~ "log(x+1) o sqrt: contiene ceros",
      TRUE            ~ "ninguna"
    )
  ) %>%
  ungroup() %>%
  transmute(
    variable        = skim_variable,
    mean            = numeric.mean,
    sd              = numeric.sd,
    cv,
    skewness        = round(skewness, 2),
    medcouple       = round(medcouple, 2),
    kurtosis        = round(kurtosis, 2),
    pct_outliers    = percent(prop_outliers, accuracy = 0.1),
    iqr,
    histograma      = numeric.hist,
    transform_rec   = transform_rec
  )

  knitr::kable(
    numeric_eda,
    digits = 2,
    caption = "Análisis extendido de variables numéricas"
  )

```

> **Nota sobre las medidas de asimetría:** En este análisis se reportan dos métricas complementarias para evaluar la asimetría de las variables numéricas:
>
> -   `skewness` corresponde al **coeficiente muestral de asimetría (**$g_1$), una medida **paramétrica** que mide la forma de la distribución en función del sesgo respecto a la media (mediante el tercer momento central muestral). Es sensible a valores atípicos (*outliers*) y capta la **asimetría en las colas**.
> -   `medcouple`: es un **estadístico no paramétrico y robusto** que mide la asimetría del “cuerpo central" de la distribución, sin verse afectado por outliers.
>
> Dado que ambas métricas responden a diferentes aspectos de la forma de la distribución, pueden arrojar resultados aparentemente contradictorios:
>
> -   En variables con muchos ceros y algunos valores extremos altos (como `Pool_Area` o `Misc_Val`), el `medcouple` puede ser **negativo** (indicando que la masa principal está a la derecha), mientras que el `skewness` será **positivo** por la presencia de colas largas hacia la derecha.
>
> -   En otros casos, como `Kitchen_AbvGr`, aunque la media y la mediana están alineadas (dando idea de simetría), el `skewness` puede ser alto por la naturaleza discreta de la variable (muchos 1 y pocos valores mayores).
>
> Por ello, **es recomendable interpretar ambas medidas en conjunto**: `skewness` capta simetría global, incluyendo extremos, y `medcouple` resume la simetría de la parte mas densa de la distribución. Usarlas juntas da una visión más completa sobre la simetría de cada variable.

### Calidad de Datos y Ausencia Estructural

El tratamiento de valores faltantes es una etapa clave del preprocesamiento en proyectos de datos, ya que afecta directamente las decisiones de modelado, la validez de los patrones descubiertos y la capacidad de generalización de los modelos. No todos los modelos toleran valores faltantes, y su presencia puede introducir sesgos o errores si no se trata de forma adecuada (transformaciones). Como veremos, este conjunto no contiene valores faltantes explícitos, codificaciones que indican ausencia estructural, con el objetivo de tomar decisiones informadas para su tratamiento posterior.

Falta presentar resultados esperados a partir de la literatura relevante existente (Paper "Ames, Iowa: Alternative to the Boston Housing Data" y Kaggle notebooks) y contrastar resultados.

En esta sección abordamos:

-   Valores faltantes explícitos (`NA`)
-   Codificaciones especiales como `"None"`, `"No_"`, y ceros estructurales en variables numéricas
-   Ausencia estructural implícita a partir del contexto de la variable

Además, se documentan decisiones preliminares sobre imputación, transformación o recodificación para trazabilidad futura.

#### Valores faltantes explícitos (*missing values*)

```{r missing_values}
# Resumen de NAs
n_obs <- nrow(ames_data)
na_summary <- ames_data %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "n_na") %>%
  filter(n_na > 0) %>%
  mutate(pct = round(100 * n_na / n_obs, 2)) %>%
  arrange(desc(pct))

# Tabla vacía
# knitr::kable(na_summary, caption = "Variables con valores faltantes")
cat("Número de variables con NA:", nrow(na_summary), "\n")
```

> No se detectan *missing values* explícitos en el conjunto, lo que evita imputaciones tradicionales y nos lleva a las codificaciones especiales.

#### Variables categóricas: codificaciones especiales

Para un listado exhaustivo de todos los niveles de las variables categóricas, véase la sección "Variables categóricas" del análisis descriptivo univariado.

##### Codificaciones de ausencia

Las variables categóricas que indican ausencia estructural son aquellas que el data entry representa la ausencia de la característica usando strings como "None" o "No_*".

```{r}
# Niveles que indican ausencia
none_levels <- c("None", "No_Alley_Access", "No_Pool", "No_Fence", "No_Garage", "No_Basement")

ames_data %>%
  select(where(is.factor)) %>%
  summarise(across(everything(), ~ sum(. %in% none_levels))) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "n_none") %>%
  filter(n_none > 0) %>%
  mutate(percent = percent(n_none / n_obs, accuracy = 0.1)) %>%
  arrange(desc(n_none/ n_obs)) %>%
  select(-n_none) %>%
  knitr::kable(caption = "Variables categóricas con niveles que indican ausencia estructural")
```

##### Tratamiento de codificaciones categóricas

Para guiar decisiones de preprocesamiento, agrupamiento y codificación, se resumen a continuación algunas consideraciones sobre las variables categóricas del conjunto **Ames Housing**:

###### Alta cardinalidad

-   `Neighborhood` (28 niveles) presenta una granularidad geográfica detallada. Se recomienda reagrupar niveles con \< 1 % de frecuencia en una categoría "Otros".
-   `Exterior_1st` y `Exterior_2nd` (16 niveles) pueden agruparse por material predominante (*Vinyl*, *Wood*, *Brick*, *Otros*) para facilitar interpretación y reducir dimensionalidad.

###### Categorías infrecuentes

-   Niveles como `Landmark` (en `Neighborhood`) o `VWD` (en `Sale_Type`) representan \< 1 % de las observaciones. Es prudente reagrupar estos niveles raros bajo “Other” para evitar sobreajuste y ruido en modelos supervisados.

###### Exploración de `Gar2` en `Misc_Feature`

Dado que `Gar2` (5 observaciones, 0.2 %) indica un segundo garaje, filtrá esas filas y compará sus valores de `Garage_Area`, `Garage_Cars` y `Sale_Price`.

```{r}
ames_data %>%
  filter(Misc_Feature == "Gar2") %>%
  select(Garage_Area, Garage_Cars, Sale_Price) %>%
  knitr::kable(caption = "Valores de Garage_Area, Garage_Cars y Sale_Price para Misc_Feature = 'Gar2'")
```

###### Variables binarias o casi binarias

-   Variables como `Central_Air` (93 % “Y”), `Street`, `Utilities`, `Pool_QC`, `Alley`, `Fence`, `Paved_Drive` tienen un nivel dominante \> 90 %, lo que justifica tratarlas como indicadores lógicos 0/1.

###### Agrupaciones por conocimiento de dominio

-   `MS_SubClass`: puede reagruparse en categorías como *OneStory*, *TwoStory*, *SplitLevel* para capturar la función estructural.
-   `House_Style`: simplificable en *One_Story*, *Two_Story* y *Otros estilos* para mejorar generalización.

###### Desequilibrio de niveles

-   Varias variables presentan niveles dominantes (\> 80 %), lo cual puede inducir sesgos. Este desbalance justifica métodos de regularización (Ridge, Lasso, ElasticNet) o selección de variables dummy con penalización.

#### Variables numéricas: ceros estructurales

Variables numéricas como `Garage_Area` o `MasVnr_Area` pueden contener ceros que no representan valores cuantitativos reales, sino ausencia de la característica (p.ej., `Mas_Vnr_Area = 0` cuando `Mas_Vnr_Type == "None"`). Este detalle también se resalta en notebooks de Kaggle, donde se señala que “el valor 0 puede estar indicando que el criterio no aplicaba”. Prestar especial atención al imputar o escalar estos ceros.

Listamos la frecuencia de ceros estructurales en variables numéricas

```{r}
# Porcentaje de observaciones `0` en variables numéricas
ames_data %>%
  select(where(is.numeric)) %>%
  summarise(across(everything(), ~ mean(. == 0, na.rm = TRUE))) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "zeros_prop") %>%
  filter(zeros_prop > 0) %>%
  mutate(pct_zeros = percent(zeros_prop, accuracy = 0.1)) %>%
  arrange(desc(zeros_prop)) %>%
  select(-zeros_prop) %>%
  knitr::kable(caption = "Proporción de ceros estructurales en variables numéricas")
```

##### Mapeo de variables y métricas asociadas

Exploramos la relación entre variables categóricas y numéricas que pueden tener un comportamiento estructural similar. Se mapean pares de variables categóricas (`cat_var`) y numéricas (`num_var`) relacionadas, donde el valor cero en la variable numérica puede indicar la ausencia de la característica descrita por la variable categórica.

```{r}
pares <- list(
  c("Garage_Type",     "Garage_Area"),
  c("Garage_Cond",     "Garage_Area"),
  c("Bsmt_Cond",       "Total_Bsmt_SF"), 
  c("Bsmt_Exposure",   "Total_Bsmt_SF"), 
  c("Pool_QC",         "Pool_Area"),
  c("Mas_Vnr_Type",     "Mas_Vnr_Area"),
  c("Misc_Feature",    "Misc_Val")
)

# Número total de observaciones
n_obs <- nrow(ames_data)

# Función que, dado un par (cat_var, num_var), devuelve un tibble con métricas
resumen_pareado <- function(par) {
  cat_var <- par[1]
  num_var <- par[2]

  # Filtrar none / cero
  df <- ames_data %>%
    mutate(
      is_none = .data[[cat_var]] %in% none_levels,
      is_zero = .data[[num_var]] == 0
    )

  n_none        <- sum(df$is_none,    na.rm = TRUE)
  n_zero        <- sum(df$is_zero,    na.rm = TRUE)
  n_none_zero   <- sum(df$is_none & df$is_zero, na.rm = TRUE)

  tibble(
    cat_var              = cat_var,
    num_var              = num_var,
    n_none               = n_none,
    pct_none             = percent(n_none / n_obs, accuracy = 0.1),
    n_zero               = n_zero,
    pct_zero             = percent(n_zero / n_obs, accuracy = 0.1),
    n_none_zero          = n_none_zero,
    pct_zero_given_none  = if (n_none>0) percent(n_none_zero / n_none, accuracy = 0.1) else NA_real_,
    pct_none_given_zero  = if (n_zero>0) percent(n_none_zero / n_zero, accuracy = 0.1) else NA_real_
  )
}

# Mapeamos y combinamos en un solo data.frame
tabla_ausencia <- map_dfr(pares, resumen_pareado)

knitr::kable(
  tabla_ausencia,
  caption = "Métricas de ausencia estructural por par (None vs 0)",
  col.names = c(
    "Var. Categ.", "Var. Num.",
    "count None", "pct None",
    "count 0",    "pct 0",
    "count None∧0",
    "pct 0|None", "pct None|0"
  )
)
```

> Esta tabla valida la consistencia interna y guía la ingeniería de variables, sobretodo en variables como `Garage_Area`, `Total_Bsmt_SF` y `Mas_Vnr_Area`que estan altamente correlacionadas con `Sale_Price`

##### Recomendaciones para el preprocesamiento

-   `Lot_Frontage`:
    -   Conceptualmente, toda propiedad tiene algún tipo de frente, por lo que los ceros no representan un valor válido y deben tratarse como valores faltantes `NA`.
    -   En los documentos originales del Ames Housing y en múltiples análisis reproducibles, se asume que los ceros fueron colocados en lugar de `NA` por errores de codificación o por datos no disponibles.
-   `Garage_Area` y `Garage_Cars`:
    -   Usar `Garage_Cars` como factor ordenado o dejar como entero según el modelo.
    -   Crear `has_garage = Garage_Cars > 0`
    -   Usar interacción `Garage_Area * has_garage`
    -   Usar transformación `log1p(Garage_Area)` sólo donde `Garage_Area > 0`
-   `Total_Bsmt_SF`:
    -   Crear `has_basement = Total_Bsmt_SF > 0`
    -   Transformar `log1p(Total_Bsmt_SF)` o modelar aparte para casos sin sótano.
    -   Usar interacción `Total_Bsmt_SF * has_basement`
-   `Mas_Vnr_Area`:
    -   Crear `has_veneer = Mas_Vnr_Type != "None"`
    -   Usar `NA`si `Mas_Vnr_Type == "None"`
    -   Usar transformación `log1p(Mas_Vnr_Area)` sólo donde `Mas_Vnr_Area > 0`
    -   Usar interacción `Mas_Vnr_Area * has_veneer`
-   `Pool_Area`:
    -   Crear `has_pool = Pool_QC != "None"`
    -   Usar transformación `log1p(Pool_Area)` sólo donde `Pool_Area > 0`
    -   Usar interacción `Pool_Area * has_pool`

#### Duplicados

No existe variable `Id` en el conjunto, por lo que no se puede validar unicidad de filas por identificador. Validaremos unicidad de filas por fila completa.

```{r duplicates}
# Validar unicidad de Id si existiera o por fila completa
n_duplicadas <- ames_data %>% duplicated() %>% sum()
cat("Número de filas duplicadas:", n_duplicadas, "\n")
```

> No se detectan filas duplicadas exactas.

## Análisis de la variable respuesta: Sale_Price

### Resumen estadístico

```{r target_summary}
# Resumen estadístico de Sale_Price
summary(ames_data$Sale_Price)

# Coeficiente de variación
cv_sale_price <- sd(ames_data$Sale_Price, na.rm = TRUE) / mean(ames_data$Sale_Price, na.rm = TRUE) * 100
cv_sale_price <- round(cv_sale_price, 2)

cat("Coeficiente de variación de Sale_Price:", cv_sale_price, "%\n")

skewness_value <- skewness(ames_data$Sale_Price, na.rm = TRUE)
kurtosis_value <- kurtosis(ames_data$Sale_Price, na.rm = TRUE)

cat("Asimetría:", round(skewness_value, 2), "\n")
cat("Curtosis:", round(kurtosis_value, 2), "\n")
```

### Visualización de la distribución

```{r target_distribution}
# Histograma con curva de densidad
p1 <- ames_data %>%
  ggplot(aes(x = Sale_Price)) +
  geom_histogram(aes(y = after_stat(density)), 
                 bins = 50, 
                 fill = "steelblue", 
                 color = "white", 
                 alpha = 0.8) +
  geom_density(color = "red", linewidth = 1) +
  scale_x_continuous(labels = scales::dollar) +
  labs(title = "Distribución de Precios de Venta",
       x = "Precio de Venta (USD)",
       y = "Densidad") +
  theme(plot.title = element_text(hjust = 0.5))

# QQ-plot para normalidad
p2 <- ggplot(ames_data, aes(sample = Sale_Price)) +
  stat_qq(color = "steelblue") +
  stat_qq_line(color = "red") +
  labs(title = "QQ-Plot de Normalidad",
       x = "Cuantiles Teóricos",
       y = "Cuantiles Muestrales") +
  theme(plot.title = element_text(hjust = 0.5))

# Boxplot para identificar valores atípicos
p3 <- ames_data %>%
  ggplot(aes(y = Sale_Price)) +
  geom_boxplot(fill = "steelblue", alpha = 0.7) +
  scale_y_continuous(labels = scales::dollar) +
  labs(title = "Boxplot de Precios de Venta",
       y = "Precio de Venta (USD)") +
  theme(plot.title = element_text(hjust = 0.5))

# Mostrar gráficos
(p1 + p2) / p3 + plot_layout(heights = c(2, 1))
```

### Transformación logarítmica

```{r log_transform}
# Aplicar transformación logarítmica
ames_data <- ames_data %>%
  mutate(log_Sale_Price = log(Sale_Price))

# Visualizar distribución transformada
p4 <- ames_data %>%
  ggplot(aes(x = log_Sale_Price)) +
  geom_histogram(aes(y = after_stat(density)), 
                 bins = 50, 
                 fill = "steelblue", 
                 color = "white", 
                 alpha = 0.8) +
  geom_density(color = "red", linewidth = 1) +
  labs(title = "Distribución de log(Sale_Price)",
       x = "log(Precio de Venta)",
       y = "Densidad") +
  theme(plot.title = element_text(hjust = 0.5))

# QQ-plot para normalidad de la variable transformada
p5 <- ggplot(ames_data, aes(sample = log_Sale_Price)) +
  stat_qq(color = "steelblue") +
  stat_qq_line(color = "red") +
  labs(title = "QQ-Plot de log(Sale_Price)",
       x = "Cuantiles Teóricos",
       y = "Cuantiles Muestrales") +
  theme(plot.title = element_text(hjust = 0.5))

# Mostrar gráficos transformados
p4 + p5
```

## Análisis de variables predictoras

### Variables numéricas

#### Correlación con variables numéricas

```{r numeric_correlation}
# Seleccionar solo variables numéricas
numeric_vars <- ames_data %>%
  select(where(is.numeric)) %>%
  select(-matches("^[A-Za-z]+\\.y\\.+[0-9]+\\.?[0-9]*$"))  # Eliminar columnas duplicadas

# Matriz de correlación
cor_matrix <- cor(numeric_vars, use = "complete.obs")

# Variables más correlacionadas con Sale_Price
cor_with_target <- cor_matrix[, "Sale_Price", drop = FALSE] %>%
  as.data.frame() %>%
  rownames_to_column("Variable") %>%
  arrange(desc(Sale_Price)) %>%
  filter(Variable != "Sale_Price")

# Mostrar las 15 variables más correlacionadas
head(cor_with_target, 15) %>% 
  knitr::kable(digits = 3, 
               col.names = c("Variable", "Correlación con Sale_Price"),
               caption = "Variables numéricas más correlacionadas con Sale_Price")

# Gráfico de correlación para las 10 variables más relacionadas
corrplot.mixed(cor(numeric_vars[, c("Sale_Price", head(cor_with_target$Variable, 10))], 
                  use = "complete.obs"),
               upper = "circle",
               lower.col = "black",
               number.cex = 0.7,
               tl.cex = 0.7,
               tl.pos = "lt",
               title = "Matriz de correlación - Top 10 variables")
```

#### Relaciones bivariadas con las variables más correlacionadas

```{r top_correlations}
# Función para crear scatter plots con línea de tendencia
plot_scatter <- function(data, x_var, y_var = "Sale_Price") {
  data %>%
    ggplot(aes(x = !!sym(x_var), y = !!sym(y_var))) +
    geom_point(alpha = 0.5, color = "steelblue") +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    scale_y_continuous(labels = scales::dollar) +
    labs(title = paste("Relación entre", x_var, "y Sale_Price"),
         x = x_var,
         y = "Precio de Venta (USD)") +
    theme(plot.title = element_text(size = 10, hjust = 0.5))
}

# Variables numéricas más correlacionadas (excluyendo las que tienen muchos valores únicos)
top_numeric <- cor_with_target %>%
  filter(!Variable %in% c("Id", "Mo_Sold", "Year_Sold", "Garage_Yr_Blt")) %>%
  head(6) %>%
  pull(Variable)

# Crear scatter plots
scatter_plots <- map(top_numeric, ~plot_scatter(ames_data, .x))

# Mostrar gráficos
wrap_plots(scatter_plots, ncol = 2) + 
  plot_annotation(title = 'Relación entre las variables numéricas más correlacionadas y Sale_Price',
                  theme = theme(plot.title = element_text(hjust = 0.5, size = 12)))
```

### Variables categóricas

#### Análisis de variables categóricas importantes

```{r categorical_analysis}
#| eval: false
# Función para graficar variables categóricas vs Sale_Price
plot_cat_var <- function(data, var_name, y_var = "Sale_Price") {
  data %>%
    ggplot(aes(x = reorder(!!sym(var_name), !!sym(y_var), FUN = median, na.rm = TRUE), 
               y = !!sym(y_var))) +
    geom_boxplot(fill = "steelblue", alpha = 0.7) +
    stat_summary(fun = median, geom = "point", color = "red", size = 2) +
    scale_y_continuous(labels = scales::dollar) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
          plot.title = element_text(size = 10, hjust = 0.5)) +
    labs(title = paste("Distribución de", y_var, "por", var_name),
         x = var_name,
         y = y_var)
}

# Variables categóricas relevantes basadas en conocimiento de dominio
cat_vars <- c("Neighborhood", "Overall_Cond", "Kitchen_AbvGr", "Garage_Type", 
              "Heating_QC", "Foundation", "Bsmt_Cond")

# Crear gráficos
cat_plots <- map(cat_vars, ~plot_cat_var(ames_data, .x))

# Mostrar gráficos
wrap_plots(cat_plots, ncol = 2) + 
  plot_annotation(title = 'Distribución de Sale_Price por variables categóricas',
                  theme = theme(plot.title = element_text(hjust = 0.5, size = 14)))
```

## Análisis de valores faltantes

```{r cat_missing_values}
# Función para calcular porcentaje de valores faltantes por columna
missing_summary <- function(data) {
  data %>%
    summarise(across(everything(), ~sum(is.na(.)))) %>%
    pivot_longer(everything(), names_to = "variable", values_to = "n_missing") %>%
    mutate(pct_missing = n_missing / nrow(data) * 100) %>%
    filter(n_missing > 0) %>%
    arrange(desc(pct_missing))
}

# Calcular y mostrar resumen de valores faltantes
missing_data <- missing_summary(ames_data)

# Mostrar variables con valores faltantes
if(nrow(missing_data) > 0) {
  knitr::kable(missing_data, 
               digits = 2,
               caption = "Variables con valores faltantes")
} else {
  cat("No hay valores faltantes en el conjunto.")
}

# Visualizar el patrón de valores faltantes
if(nrow(missing_data) > 0) {
  library(naniar)
  vis_miss(ames_data, sort_miss = TRUE) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8)) +
    labs(title = "Patrón de valores faltantes en el conjunto")
}
```

## Análisis de valores atípicos

```{r outliers_analysis}
# Función para identificar valores atípicos usando el método IQR
get_outliers <- function(x) {
  qnt <- quantile(x, probs = c(0.25, 0.75), na.rm = TRUE)
  iqr <- IQR(x, na.rm = TRUE)
  lower <- qnt[1] - 1.5 * iqr
  upper <- qnt[2] + 1.5 * iqr
  list(lower = lower, upper = upper, outliers = x[x < lower | x > upper])
}

# Identificar valores atípicos en Sale_Price
outliers_sale_price <- get_outliers(ames_data$Sale_Price)

# Mostrar resumen de valores atípicos
cat("Límite inferior para valores atípicos:", scales::dollar(outliers_sale_price$lower), "\n")
cat("Límite superior para valores atípicos:", scales::dollar(outliers_sale_price$upper), "\n")
cat("Número de valores atípicos:", length(outliers_sale_price$outliers), "\n")
cat("Porcentaje de valores atípicos:", 
    round(length(outliers_sale_price$outliers) / nrow(ames_data) * 100, 2), "%\n")

# Visualizar valores atípicos
ames_data %>%
  mutate(is_outlier = if_else(Sale_Price > outliers_sale_price$upper | 
                              Sale_Price < outliers_sale_price$lower, 
                            "Atípico", "Normal")) %>%
  ggplot(aes(x = "", y = Sale_Price, fill = is_outlier)) +
  geom_boxplot() +
  scale_fill_manual(values = c("Atípico" = "red", "Normal" = "steelblue")) +
  scale_y_continuous(labels = scales::dollar) +
  labs(title = "Identificación de valores atípicos en Sale_Price",
       x = "",
       y = "Precio de Venta (USD)",
       fill = "Clasificación") +
  theme(legend.position = "bottom")
```

## Conclusiones y recomendaciones para el modelado

### Hallazgos principales

-   **Variable respuesta (Sale_Price)**:
    -   Distribución asimétrica a la derecha, con una cola larga hacia valores altos
    -   Coeficiente de variación del XX% indica una variabilidad moderada en los precios
    -   La transformación logarítmica mejora significativamente la normalidad de la distribución
-   **Variables numéricas más relevantes**:
    -   `Overall_Qual`, `Gr_Liv_Area`, `Garage_Cars`, `Garage_Area` y `Total_Bsmt_SF` muestran las correlaciones más fuertes con `Sale_Price`
    -   Se observan relaciones aproximadamente lineales con la variable respuesta
-   **Variables categóricas importantes**:
    -   `Neighborhood` muestra una gran variabilidad en los precios entre barrios
    -   `Overall_Qual` y `Kitchen_Qual` tienen una fuerte relación con el precio de venta
    -   La calidad de los materiales y el acabado (`Exter_Qual`, `Bsmt_Qual`) también son predictores importantes
-   **Valores faltantes**:
    -   Varias variables tienen valores faltantes que deberán ser manejados
    -   Algunas variables como `Pool_QC`, `Misc_Feature` y `Alley` tienen una alta proporción de valores faltantes
-   **Valores atípicos**:
    -   Se identificaron XX valores atípicos en `Sale_Price` (aproximadamente YY% de los datos)
    -   Estos valores podrían ser casas de lujo o errores de medición

### Recomendaciones para el modelado

-   **Preprocesamiento**:
    -   Aplicar transformación logarítmica a `Sale_Price` para manejar la asimetría
    -   Considerar la eliminación o imputación de variables con alta proporción de valores faltantes
    -   Estandarizar o normalizar las variables numéricas
    -   Codificar las variables categóricas (one-hot encoding o target encoding)
-   **Selección de características**:
    -   Incluir las variables más correlacionadas identificadas en el análisis
    -   Considerar la creación de características derivadas (ej: área total = área del primer piso + área del segundo piso)
    -   Evaluar la multicolinealidad entre predictores
-   **Validación del modelo**:
    -   Utilizar validación cruzada para una mejor estimación del rendimiento
    -   Considerar métricas robustas como el error absoluto mediano (MAE) además del RMSE
    -   Evaluar el rendimiento en diferentes rangos de precios
-   **Manejo de valores atípicos**:
    -   Evaluar el impacto de incluir/excluir valores atípicos
    -   Considerar modelos robustos a valores atípicos
-   **Consideraciones adicionales**:
    -   Evaluar interacciones entre variables (ej: efecto del barrio en la relación entre área y precio)
    -   Considerar efectos no lineales en las relaciones
    -   Evaluar la importancia de las variables en el modelo final

Este análisis proporciona una base sólida para el desarrollo de un modelo de regresión para predecir el precio de venta de viviendas. Se recomienda utilizar estos hallazgos para guiar las decisiones de preprocesamiento y selección de características en el modelo final.